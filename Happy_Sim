library(readr)
library(gam)
library(dplyr)
library(ggplot2)
library(MASS)
library(tidyr)
# ----- 함수 ----- #
find_lambda <- function(alpha, delta, y, pred, variance, n, lower=0, upper=30, step=1e-3){
  threshold <- max(0, alpha-sqrt(log(1/delta)/(2*n)))
  lambda_seq <- seq(lower, upper, by=step)
  for (lambda in lambda_seq){
    risk <- mean(y <= pred - sqrt(variance)*lambda | y >= pred + sqrt(variance)*lambda, na.rm=TRUE)
    if (risk <= threshold) return(lambda)
  } 
  return(NA)
}

find_k_factor <- function(nu, norm_lx_h, P, gamma){
  sqrt(nu*qchisq(p=P, df=1, ncp=norm_lx_h^2) / qchisq(p=1-gamma, df=nu))
}

compute_norm <- function(vector){
  return(sqrt(sum(vector^2)))
}

compute_norm_fast <- function(B, A, BtB){
  # returns vector: ||S_{:,j}|| for j = 1,...,n
  # S_{:,j} = B %*% A %*% t(B[j, ])
  
  M <- A %*% BtB %*% A          # small matrix (df x df)
  
  # 각 j에 대해: B[j, ] %*% M %*% t(B[j, ])
  sqrt(rowSums((B %*% M) * B))
}

tf  <- function(y) log1p(y)
itf <- function(z) expm1(z)



library(readr)
library(gam)
library(dplyr)
library(ggplot2)
library(MASS)
library(tidyr)

local_path <- 'photoz_data'

# data 
data_path <- file.path(local_path, 'Happy', 'happy_A')
data <- read_delim(data_path, delim=' ', comment='#', col_names=FALSE, trim_ws=TRUE)
colnames(data) <- c(
  "id", "mag_r", "u_g", "g_r", "r_i", "i_z",
  "z_spec", "feat1", "feat2", "feat3", "feat4", "feat5"
)

# data visualization
ggplot(data, aes(x=mag_r, y=z_spec))+
  geom_point(alpha=0.2)

data <- data.frame(x=data$mag_r, y=data$z_spec)

# data sampling
set.seed(123)
data_sample <- data %>% sample_n(5000)

x <- data_sample$x
y <- data_sample$y
n <- length(x)

n_train <- floor(n*0.5)
n_cal <- floor(n*0.5)

idx <- sample(n)
train_idx <- idx[1:n_train]
cal_idx <- idx[(n_train + 1):(n_train + n_cal)]
train_x <- x[train_idx]; train_y <- y[train_idx]
cal_x <- x[cal_idx]; cal_y <- y[cal_idx]


#test data
test_data <- read_delim(file='photoz_data/Happy/happy_B', delim=' ', comment='#', col_names=FALSE)
colnames(test_data) <- c(
  "id", "mag_r", "u_g", "g_r", "r_i", "i_z",
  "z_spec", "feat1", "feat2", "feat3", "feat4", "feat5"
)
test_x <- test_data$mag_r
test_y <- test_data$z_spec


#####################
#### 1. Ours #####
#####################

# ----- 한 번 실행 함수로 감싸기 -----
one_run <- function(seed_split){
  
  set.seed(seed_split)
  # (0) 매번 Happy A에서 새로 5000 샘플링
  data_sample <- data %>% sample_n(5000)
  
  x_all <- data_sample$x
  y_all <- data_sample$y
  n <- length(x_all)
  
  n_train <- floor(n * 0.5)
  n_cal   <- n - n_train
  
  idx <- sample(n)
  train_idx <- idx[1:n_train]
  cal_idx   <- idx[(n_train + 1):(n_train + n_cal)]
  
  train_x <- x_all[train_idx]; train_y <- y_all[train_idx]
  cal_x   <- x_all[cal_idx];   cal_y   <- y_all[cal_idx]
  
  # ---- test set (Happy B) ----
  test_x <- test_data$mag_r
  test_y <- test_data$z_spec
  
  alpha <- 0.10
  delta <- 0.05
  
  # ===== log1p transform =====
  train_z <- tf(train_y)
  cal_z   <- tf(cal_y)
  test_z  <- tf(test_y)
  
  
  # ---------------------------
  # (1) Ours (on z-scale)
  # ---------------------------
  
  fit <- smooth.spline(train_x, train_z)
  
  train_res <- train_z - predict(fit, train_x)$y
  var_fit <- gam(train_res^2 ~ s(train_x))
  
  mean_pred_z <- predict(fit, cal_x)$y
  var_pred    <- predict(var_fit, newdata = data.frame(train_x = cal_x))
  var_pred[var_pred < 0] <- 1e-6
  
  lambda_hat <- find_lambda(
    alpha, delta,
    y = cal_z,
    pred = mean_pred_z,
    variance = var_pred,
    n = n_cal,
    lower = 0, upper = 30, step = 1e-3
  )
  
  if (is.na(lambda_hat)) {
    return(data.frame(
      seed = seed_split,
      ours_cov = NA_real_, ours_w = NA_real_,
      gy_cov   = NA_real_, gy_w   = NA_real_,
      lambda_hat = NA_real_
    ))
  }
  
  upper_cal_z <- mean_pred_z + sqrt(var_pred) * lambda_hat
  lower_cal_z <- mean_pred_z - sqrt(var_pred) * lambda_hat
  
  # interpolate on z-scale, then back-transform
  upper_ours_z <- approx(x = cal_x, y = upper_cal_z, xout = test_x, rule = 2)$y
  lower_ours_z <- approx(x = cal_x, y = lower_cal_z, xout = test_x, rule = 2)$y
  
  upper_ours <- itf(upper_ours_z)
  lower_ours <- itf(lower_ours_z)
  
  # optional clipping to enforce nonnegative lower bound
  lower_ours <- pmax(lower_ours, 0)
  
  ours_cov <- mean(test_y >= lower_ours & test_y <= upper_ours, na.rm = TRUE)
  ours_w   <- mean(upper_ours - lower_ours, na.rm = TRUE)
  
  # ---------------------------
  # (2) GY (on z-scale)
  # ---------------------------
  proper_train_idx <- idx[1:(n_train + n_cal)]
  gy_x <- x_all[proper_train_idx]
  gy_y <- y_all[proper_train_idx]
  gy_z <- tf(gy_y)
  
  gy_fit <- smooth.spline(x = gy_x, y = gy_z)
  gy_train_residual <- gy_z - predict(gy_fit, gy_x)$y
  
  gy_var_fit <- gam(gy_train_residual^2 ~ s(gy_x))
  gy_variance_hat <- predict(gy_var_fit, newdata = data.frame(gy_x = gy_x))
  gy_variance_hat <- pmax(gy_variance_hat, 1e-6)
  
  transform_y <- gy_z / sqrt(gy_variance_hat)
  gy_fit_trans <- smooth.spline(x = gy_x, y = transform_y)
  
  Bmat <- bs(gy_x, df = gy_fit_trans$df)
  D <- diff(diag(ncol(Bmat)), differences = 2)
  
  BtB <- crossprod(Bmat)
  A   <- ginv(BtB + gy_fit_trans$lambda * crossprod(D))
  
  residuals2 <- transform_y - predict(gy_fit_trans, gy_x)$y
  est_var <- as.numeric(crossprod(residuals2) / (nrow(Bmat) - 1))
  
  nu <- length(gy_x) - 1
  
  norm_lx_h_values <- compute_norm_fast(Bmat, A, BtB)
  
  k_factors <- find_k_factor(
    nu,
    norm_lx_h_values,
    P = 1 - alpha,
    gamma = delta
  )
  
  gy_mean_pred <- predict(gy_fit_trans, gy_x)$y
  gy_upper_t <- gy_mean_pred + sqrt(est_var) * k_factors
  gy_lower_t <- gy_mean_pred - sqrt(est_var) * k_factors
  
  # back to z-scale
  gy_upper_z <- gy_upper_t * sqrt(gy_variance_hat)
  gy_lower_z <- gy_lower_t * sqrt(gy_variance_hat)
  
  # interpolate on z-scale to test_x
  upper_gy_z <- approx(x = gy_x, y = gy_upper_z, xout = test_x, rule = 2)$y
  lower_gy_z <- approx(x = gy_x, y = gy_lower_z, xout = test_x, rule = 2)$y
  
  # back-transform to original y scale
  upper_gy <- itf(upper_gy_z)
  lower_gy <- itf(lower_gy_z)
  lower_gy <- pmax(lower_gy, 0)
  
  gy_cov <- mean(test_y >= lower_gy & test_y <= upper_gy, na.rm = TRUE)
  gy_w   <- mean(upper_gy - lower_gy, na.rm = TRUE)
  
  data.frame(
    seed = seed_split,
    ours_cov = ours_cov, ours_w = ours_w,
    gy_cov   = gy_cov,   gy_w   = gy_w,
    lambda_hat = lambda_hat
  )
}

# 병렬처리 # 
library(future)
library(future.apply)
library(dplyr)

seeds <- 1:100

plan(multisession, workers = max(1L, parallel::detectCores() - 1L))

res <- bind_rows(future_lapply(seeds, one_run, future.seed = TRUE))

plan(sequential)


# ----- 요약 (평균/표준오차) -----
summ <- res %>%
  summarise(
    B = n(),
    fail_lambda = mean(is.na(lambda_hat)),
    ours_cov_mean = mean(ours_cov, na.rm=TRUE),
    ours_cov_se   = sd(ours_cov, na.rm=TRUE) / sqrt(sum(!is.na(ours_cov))),
    ours_w_mean   = mean(ours_w, na.rm=TRUE),
    ours_w_se     = sd(ours_w, na.rm=TRUE) / sqrt(sum(!is.na(ours_w))),
    gy_cov_mean   = mean(gy_cov, na.rm=TRUE),
    gy_cov_se     = sd(gy_cov, na.rm=TRUE) / sqrt(sum(!is.na(gy_cov))),
    gy_w_mean     = mean(gy_w, na.rm=TRUE),
    gy_w_se       = sd(gy_w, na.rm=TRUE) / sqrt(sum(!is.na(gy_w)))
  )

print(summ)

library(dplyr)
library(tidyr)
library(ggplot2)
library(patchwork)

# (0) long format
plot_df <- res %>%
  dplyr::select(seed, ours_cov, gy_cov, ours_w, gy_w) %>%
  pivot_longer(
    cols = -seed,
    names_to = c("method", "metric"),
    names_sep = "_",
    values_to = "value"
  ) %>%
  mutate(
    method = recode(method, ours = "Ours", gy = "GY"),
    method = factor(method, levels = c("Ours", "GY")),
    metric = recode(metric,
                    cov = "Coverage",
                    w   = "Width")
  )

fill_cols <- c("Ours" = "tomato", "GY" = "skyblue")

# 공통 theme (논문용)
theme_paper <- theme_bw(base_size = 12) +
  theme(
    legend.position = "none",
    panel.grid.major = element_line(linewidth = 0.2),
    panel.grid.minor = element_blank(),
    plot.title = element_text(size = 13, face = "bold", hjust = 0.5),
    axis.title.x = element_blank(),
    axis.title.y = element_text(size = 11),
    axis.text = element_text(size = 10),
    plot.margin = margin(5.5, 6, 5.5, 6)
  )

# (1) Coverage panel
df_cov <- plot_df %>% filter(metric == "Coverage")

p_cov <- ggplot(df_cov, aes(x = method, y = value, fill = method)) +
  geom_boxplot(
    width = 0.55, alpha = 0.55, outlier.shape = NA,
    linewidth = 0.35, color = "grey25"
  ) +
  # 점은 조금만, 겹침 줄이기
  geom_point(
    position = position_jitter(width = 0.12, height = 0),
    size = 1.1, alpha = 0.35, color = "grey15"
  ) +
  geom_hline(yintercept = 0.90, linetype = "dashed", linewidth = 0.5) +
  scale_fill_manual(values = fill_cols) +
  labs(title = "Coverage", y = "Marginal coverage") +
  # 보기 좋게 범위 자동 + 약간 여유
  coord_cartesian(ylim = range(df_cov$value, na.rm = TRUE) + c(-0.01, 0.01)) +
  theme_paper

# (2) Width panel
df_w <- plot_df %>% filter(metric == "Width")

p_w <- ggplot(df_w, aes(x = method, y = value, fill = method)) +
  geom_boxplot(
    width = 0.55, alpha = 0.55, outlier.shape = NA,
    linewidth = 0.35, color = "grey25"
  ) +
  geom_point(
    position = position_jitter(width = 0.12, height = 0),
    size = 1.1, alpha = 0.35, color = "grey15"
  ) +
  scale_fill_manual(values = fill_cols) +
  labs(title = "Width", y = "Mean interval width") +
  coord_cartesian(ylim = range(df_w$value, na.rm = TRUE) + c(-0.02, 0.02)) +
  theme_paper

# (3) Combine
p_final <- p_cov + p_w + plot_layout(ncol = 2)
p_final
