library(splines)
library(foreach)
library(progressr)
library(doFuture)
library(future)
library(splines)
library(MASS)


# ğŸ”¥ 2. í•„ìš”í•œ í•¨ìˆ˜ ì •ì˜

# ë°ì´í„° ìƒì„± í•¨ìˆ˜ ì •ì˜
generate_data <- function(model, n) {
  #x <- sort(runif(n, 0, 10)) # xë„ ëœë¤í•˜ê²Œ ìƒì„±
  x <- seq(0, 10, length.out=n)
  base <- 3 * cos(x) - 5 * (x / 15)^2
  
  if (model == 1) {
    y <- base + rnorm(n, mean = 0, sd = sqrt(2))
  }
  if (model == 2) {
    y <- base + rnorm(n, mean = 0, sd = sqrt(2 * x))
  }
  if (model == 3) {
    y <- base + 4 - rgamma(n, shape = 2, scale = 2)
  }
  if (model == 4) {
    y <- base + rt(n, df = 3)
  }
  if (model == 5) {
    sd_x <- 0.3 + 3 * exp(-(x - 5)^2 / (2 * 1.5^2))
    y <- base + rnorm(n, mean = 0, sd = sd_x)
  }
  if (model == 6) {
    y <- base + rnorm(n, mean = 0, sd = 1) + abs(rnorm(n, 0, 1)) - sqrt(2/pi)
  }
  if (model == 7) {
    noise <- ifelse(runif(n) < 0.5, rnorm(n, mean = -3, sd = 1), rnorm(n, mean = 3, sd = 1))
    y <- base + noise
  }
  
  if (model == 8) {
    noise <- ifelse(x < 5,
                    rnorm(n, mean = -2, sd = 1 + 0.5 * x),
                    rnorm(n, mean = 2, sd = 2 - 0.3 * (x - 5)))
    y <- base + noise
  }
  
  return(data.frame(x = x, y = y))
}


# ë²¡í„°ì˜ L2 norm ê³„ì‚° í•¨ìˆ˜
compute_norm <- function(vector) {
  return(sqrt(sum(vector^2)))
}

# ê·¼ì‚¬ë¡œ k factor ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜ 
find_k_factor_fast <- function(nu, norm_lx_h, P = 0.90, gamma = 0.95) {
  sqrt(nu * qchisq(p = P, df = 1, ncp = norm_lx_h^2) / qchisq(p = 1 - gamma, df = nu))
}

# k factor ê°€ì ¸ì˜¤ê¸° (ìºì‹œ ì‚¬ìš©)
get_k_factor <- function(nu, norm_lx_h) {
  key <- as.character(round(norm_lx_h, 2))  # ì†Œìˆ˜ì  2ìë¦¬ê¹Œì§€
  if (exists(key, envir = k_lookup_global)) {
    return(get(key, envir = k_lookup_global))
  } else {
    k_value <- find_k_factor_fast(nu, norm_lx_h)
    assign(key, k_value, envir = k_lookup_global)
    return(k_value)
  }
}

# ğŸ”¥ 3. ë©”ì¸ í•¨ìˆ˜ (transform and evaluate)
transform_and_evaluate_sequential <- function(models, sample_sizes, M, seed) {
  set.seed(seed)
  monte_carlo_results <- list()
  
  for (model in models) {
    for (m in sample_sizes) {
      cat(sprintf("\n[START] Model: %d, Sample size: %d\n", model, m))
      start_time_model <- Sys.time()
      
      lambda_list <- numeric(M)
      
      for (i in 1:M) {
        data_i <- generate_data(model, m)
        x <- data_i$x
        y <- data_i$y
        
        fit <- tryCatch({
          smooth.spline(x = x, y = y, cv = TRUE)
        }, error = function(e) {
          warning(sprintf("âš ï¸ smoothing ì‹¤íŒ¨: %s", e$message))
          return(NULL)
        })
        
        if (!is.null(fit) && !is.null(fit$lambda) && is.finite(fit$lambda)) {
          lambda_list[i] <- fit$lambda
        } else {
          lambda_list[i] <- NA
        }
      }
      
      mean_lambda <- mean(lambda_list, na.rm = TRUE)
      cat(sprintf("ğŸŒŸ í‰ê·  lambda (Model %d, m=%d): %.5f\n", model, m, mean_lambda))
      
      results_list <- list()
      
      for (i in 1:M) {
        #cat(sprintf("ğŸŒ± Seed %d ì‹œì‘ ...\n", i + seed * 1000))
        set.seed(i + seed * 1000)
        data_i <- generate_data(model, m)
        x <- data_i$x
        y <- data_i$y
        
        train_x <- x; train_y <- y
        
        set.seed(i + seed * 10000)
        test_data <- generate_data(model, 1e+6)
        test_x <- test_data$x; test_y <- test_data$y
        
        fit <- smooth.spline(x = train_x, y = train_y, cv = FALSE, lambda = mean_lambda)
        pred_train <- predict(fit, train_x)$y
        residuals <- train_y - pred_train
        
        log_variance_fit <- smooth.spline(train_x, log(residuals^2 + 1e-6), cv = FALSE)
        variance_hat_train <- exp(predict(log_variance_fit, train_x)$y)
        
        transform_y_train <- train_y / sqrt(variance_hat_train)
        fit_trans <- smooth.spline(train_x, transform_y_train, cv = FALSE)
        
        B <- bs(train_x, df = fit_trans$df)
        D <- diff(diag(ncol(B)), differences = 2)
        S_inv <- ginv(t(B) %*% B + fit_trans$lambda * t(D) %*% D)
        S <- B %*% S_inv %*% t(B)
        I_n <- diag(length(train_x))
        R <- I_n - S
        
        residuals2 <- transform_y_train - predict(fit_trans, train_x)$y
        est_var <- (t(residuals2) %*% residuals2) / sum(diag(t(R) %*% R))
        est_var <- ifelse(is.na(est_var) | is.nan(est_var) | is.infinite(est_var), 1e-6, est_var)
        
        num <- sum(diag(t(R) %*% R))^2
        den <- sum(diag((t(R) %*% R)^2))
        nu <- num / den
        
        norm_lx_h_values <- sapply(1:ncol(S), function(j) compute_norm(S[, j]))
        k_factors <- sapply(norm_lx_h_values, function(nlh) get_k_factor(nu, nlh))
        
        TI_upper <- pred_train + sqrt(est_var) * k_factors
        TI_lower <- pred_train - sqrt(est_var) * k_factors
        TI_upper <- TI_upper * sqrt(variance_hat_train)
        TI_lower <- TI_lower * sqrt(variance_hat_train)
        
        TI_lower_df <- aggregate(TI_lower ~ train_x, FUN = mean)
        TI_upper_df <- aggregate(TI_upper ~ train_x, FUN = mean)
        
        interp_lower <- approx(x = TI_lower_df$train_x, y = TI_lower_df$TI_lower, xout = test_x, rule = 2)$y
        interp_upper <- approx(x = TI_upper_df$train_x, y = TI_upper_df$TI_upper, xout = test_x, rule = 2)$y
        
        # âœ… TI ë²”ìœ„ ê³„ì‚°ëœ ì´í›„ test ë°ì´í„°ì™€ ë¹„êµ
        covered <- (test_y >= interp_lower) & (test_y <= interp_upper)
        coverage_rate <- mean(covered)

        # 90% ì´ìƒ ì»¤ë²„í–ˆëŠ”ì§€ ì—¬ë¶€ ê¸°ë¡
        is_covered <- coverage_rate >= 0.90
        
        # ì‹œë®¬ ê²°ê³¼ ì €ì¥
        results_list[[i]] <- list(
          is_covered = is_covered,
          mean_width = mean(TI_upper - TI_lower),
          NMPIW = mean((TI_upper - TI_lower) / (max(test_y) - min(test_y)))
        )
}

      
    # ìš”ì•½ ê²°ê³¼ ê³„ì‚°
    empirical_coverage <- mean(sapply(results_list, function(res) res$is_covered))
    mean_width <- mean(sapply(results_list, function(res) res$mean_width))
    nmpiw <- mean(sapply(results_list, function(res) res$NMPIW))
    
    monte_carlo_results[[paste0("Model_", model, "_m_", m)]] <- 
      data.frame(
        Model = model,
        SampleSize = m,
        EmpiricalCoverage = empirical_coverage,
        MeanWidth = mean_width,
        NMPIW = nmpiw
      )

    end_time_model <- Sys.time()
    duration <- round(difftime(end_time_model, start_time_model, units = "mins"), 2)
    cat(sprintf("[END] Model: %d, Sample size: %d â€” %.2f minutes\n", model, m, duration))

  }
  
  cat("ğŸ’¾ k_lookup_global ìºì‹œ ì €ì¥ ì¤‘...\n")
  saveRDS(k_lookup_global, k_lookup_path)
  
  return(monte_carlo_results)
}

seed = 123
M=500
models <- 1:8
sample_sizes <- c(50, 100, 200, 500, 1000)

# ê²°ê³¼ ì €ì¥ 
k_lookup_global <- new.env()
k_lookup_path <- "k_lookup_global.rds"

monte_carlo_results <- list()
monte_carlo_results <- transform_and_evaluate_sequential(models, sample_sizes, M, seed=seed)


# ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ì •ë¦¬
results <- monte_carlo_results
summary_df <- do.call(rbind, lapply(names(results), function(name) {
  df <- monte_carlo_results[[name]]
  df_summary <- data.frame(
    Model = sub("Model_(\\d+)_.*", "\\1", name),
    SampleSize = sub("._m_(\\d+)", "\\1", name),
    PICP = round(mean(df$coverage_probabilities, na.rm=TRUE),4),
    NMPIW = round(mean(df$NMPIW, na.rm=TRUE),4)
  )
  return(df_summary)
}))

write.csv(summary_df, "0514_paper_simulation_result.csv", row.names = FALSE)


summary_df
summary_df$SampleSize <- as.integer(gsub("Model_", "", summary_df$SampleSize))
summary_df$Model <- as.integer(summary_df$Model)
summary_df <- summary_df[order(summary_df$Model, summary_df$SampleSize), ]

library(knitr)
kable(summary_df, caption='Paper ëª¨ë¸ìˆ˜ì •(kê·¼ì‚¬, test # : 1e+6)')





# ì „ì²´ ëª¨ë¸ë³„, ìƒ˜í”Œ ì‚¬ì´ì¦ˆë³„ plot
library(ggplot2)
library(dplyr)

pointwise_coverage_summary <- do.call(rbind, lapply(names(monte_carlo_results), function(name) {
  df <- monte_carlo_results[[name]]
  
  if (!("coverage_probabilities" %in% names(df))) return(NULL)
  
  df <- df[!is.na(df$coverage_probabilities), ]  # NA ì œê±°
  if (nrow(df) == 0) return(NULL)  # ì „ë¶€ NAë©´ skip
  
  model <- as.integer(sub("Model_(\\d+)_m_.*", "\\1", name))
  m <- as.integer(sub(".*_m_(\\d+)", "\\1", name))
  
  data.frame(
    Model = model,
    SampleSize = m,
    x = df$x,
    Coverage = df$coverage_probabilities,
    mean_width = df$mean_width,
    NMPIW = df$NMPIW
  )
}))

picp_nmpiw_summary <- pointwise_coverage_summary %>%
  group_by(Model, SampleSize) %>%
  summarise(
    PICP = round(mean(Coverage, na.rm = TRUE), 3),
    NMPIW = round(mean(NMPIW, na.rm = TRUE), 3)
  )

plot_data <- pointwise_coverage_summary %>%
  left_join(picp_nmpiw_summary, by = c("Model", "SampleSize"))



# ì €ì¥í•  ë””ë ‰í† ë¦¬ ì„¤ì • (í•„ìš”ì‹œ ìƒì„±)
dir.create("paper_picp_plots", showWarnings = FALSE)

# ëª¨ë¸ë³„ë¡œ plot ì €ì¥
for (model_id in unique(plot_data$Model)) {
  plot_i <- plot_data %>%
    filter(Model == model_id)
  
  p <- ggplot(plot_i, aes(x = x, y = Coverage)) +
    geom_line(color = "blue", alpha = 0.6) +
    geom_hline(yintercept = 0.90, linetype = "dashed", color = "red") +
    facet_wrap(~SampleSize, ncol = 1) +
    labs(title = paste("Model", model_id, " - Pointwise Coverage (PICP)"),
         y = "Coverage Probability",
         x = "x") +
    ylim(0, 1) +
    theme_minimal(base_size = 14)
  
  ggsave(sprintf("paper_picp_plots/Model_%d_PICP_plot.png", model_id),
         plot = p, width = 8, height = 12)
}
