find_lambda_hat <- function(alpha, delta, y, pred, variance, n, lower=0, upper=5){
  f <- function(lambda, alpha, delta, y, pred, variance, n){
    risk <- mean(y <= pred - sqrt(variance)*lambda |
                   y >= pred + sqrt(variance)*lambda, na.rm=TRUE)
    threshold <- (1 - alpha) - sqrt(log(1/delta) / (2*n))
    return(risk - threshold)
  }
  lambda_hat <- tryCatch({
    uniroot(f, interval=c(lower, upper), alpha=alpha, delta=delta,
            y=y, pred=pred, variance=variance, n=n)$root
  }, error=function(e){
    optimize(function(lambda) f(lambda, alpha, delta, y, pred, variance, n),
             interval = c(lower, upper))$minimum
  })
  return(lambda_hat)
}

# trimmed mean í•¨ìˆ˜
trimmed_mean <- function(x, trim_ratio = 0.05) {
  return(mean(x, trim = trim_ratio))
}

# ê²°ê³¼ ì €ìž¥
results_summary_hoeffding <- data.frame(
  x1 = character(),
  x2 = character(),
  x3 = character(),
  mean_PICP = numeric(),
  mean_NMPIW = numeric(),  
  mean_time = numeric(),
  stringsAsFactors = FALSE
)



#-----------------------------------------------------------# í•„ìš”í•œ í•¨ìˆ˜ ##

library(splines)
library(gam)
library(mgcv)
library(fields)

library(MASS)


data <- read.csv('~/Data/plasma.csv')

# ë³€ìˆ˜ ëª©ë¡
all_vars <- c("BETADIET", "CALORIES", "CHOLESTEROL", "FAT", 
              "FIBER", "QUETELET", "RETDIET", "AGE")
target_y <- data$BETAPLASMA

# 3ì°¨ì› ë³€ìˆ˜ ì¡°í•© ìƒì„±
var_combinations <- combn(all_vars, 3, simplify = FALSE)

for (vars in var_combinations) {
  x1_name <- vars[1]; x2_name <- vars[2]; x3_name <- vars[3]
  cat(sprintf("\nðŸ”§ í˜„ìž¬ ì¡°í•©: x1 = %s, x2 = %s, x3 = %s\n", x1_name, x2_name, x3_name))
  
  picp_list <- c(); nmpiw_list <- c(); time_list <- c()
  
  for (s in 1:50) {
    cat(sprintf("  â–¶ï¸ Seed %d ì‹œìž‘...\n", s))
    start_time <- Sys.time()
    set.seed(s)
    
    x1 <- data[[x1_name]]; x2 <- data[[x2_name]]; x3 <- data[[x3_name]]
    y <- target_y
    complete_idx <- complete.cases(x1, x2, x3, y)
    x1 <- x1[complete_idx]; x2 <- x2[complete_idx]; x3 <- x3[complete_idx]; y <- y[complete_idx]
    
    n <- length(y)
    n_train <- 100
    n_cal <- 100
    n_test <- n- n_train - n_cal #115
    
    all_indices <- sample(seq_len(n))
    train_idx <- all_indices[1:n_train]
    cal_idx <- all_indices[(n_train+1):(n_train+n_cal)]
    test_idx <- all_indices[(n_train+n_cal+1):n]
    
    # ë°ì´í„° (2d) (with scaling)
    # train setë§Œìœ¼ë¡œ í‰ê· ê³¼ í‘œì¤€íŽ¸ì°¨ ì¶”ì •
    train_mean_x1 <- mean(x1[train_idx])
    train_sd_x1   <- sd(x1[train_idx])
    
    train_mean_x2 <- mean(x2[train_idx])
    train_sd_x2   <- sd(x2[train_idx])
    
    train_mean_x3 <- mean(x3[train_idx])
    train_sd_x3 <- sd(x3[train_idx])
    
    train_mean_y <- mean(y[train_idx])
    train_sd_y   <- sd(y[train_idx])
    
    # train/cal/test ê°ê° ë™ì¼ ê¸°ì¤€ìœ¼ë¡œ scaling 
    x1 <- (x1-train_mean_x1) / train_sd_x1
    x2 <- (x2-train_mean_x2) / train_sd_x2
    x3 <- (x3-train_mean_x3) / train_sd_x3
    y <- (y - train_mean_y) / train_sd_y
    
    train_x <- data.frame(x1 = x1[train_idx], x2 = x2[train_idx], x3 = x3[train_idx])
    train_y <- y[train_idx]
    cal_x <- data.frame(x1=x1[cal_idx], x2 = x2[cal_idx], x3=x3[cal_idx])
    cal_y <- y[cal_idx]
    test_x <- data.frame(x1 = x1[test_idx], x2 = x2[test_idx], x3 = x3[test_idx])
    test_y <- y[test_idx]
    
    
    # 1. Train data ì´ìš©í•´ ëª¨ë¸ í•™ìŠµ (í‰ê·  ì˜ˆì¸¡ê°’ ê³„ì‚°)
    fit <- gam(train_y ~ te(x1, x2, x3, k=c(4,4,4)), data = train_x) #trainìœ¼ë¡œ ë§Œë“  í‰ê· ì¶”ì • ëª¨ë¸
    cal_mean_pred <- predict(fit, newdata = cal_x) #calë¡œ í‰ê· ì˜ˆì¸¡
    
    # 2. Calibration dataë¡œ ì˜ˆì¸¡ ì˜¤ì°¨ì˜ ë¶„ì‚° ì¶”ì • (log scale)
    train_res <- train_y - predict(fit, newdata=train_x)
    log_res2 <- log(train_res^2+1e-8) #log transformation
    
    gam_model <- gam(log_res2~te(x1,x2,x3, k=c(4,4,4)), data=train_x) #trainìœ¼ë¡œ ë§Œë“  ë¶„ì‚°ì¶”ì • ëª¨ë¸
    log_pred <- predict(gam_model, newdata= cal_x) #calë¡œ ë¶„ì‚° ì˜ˆì¸¡
    cal_variance <- exp(log_pred) 
    
    # 3. Tolerance Interval ê³„ì‚° (ë¶„ì‚° í¬í•¨)
    lambda_hat <- find_lambda_hat(alpha=0.95, delta=0.90, cal_y, cal_mean_pred, cal_variance, length(cal_y))
    
    TI_upper <- cal_mean_pred + sqrt(cal_variance) * lambda_hat
    TI_lower <- cal_mean_pred - sqrt(cal_variance) * lambda_hat
    
    
    # 4. ì™¸ì‚½ ë³´ê°„ì„ ì´ìš© : Thin Plate Spline ëª¨ë¸ì„ ìƒˆë¡­ê²Œ ìƒì„±
    library(fields)
    tps_lower <- gam(TI_lower ~ te(x1, x2, x3, k=c(4,4,4)), data = train_x)
    tps_upper <- gam(TI_upper ~ te(x1, x2, x3,  k=c(4,4,4)), data = train_x)
    
    test_TIlower <- predict(tps_lower, newdata = test_x)
    test_TIupper <- predict(tps_upper, newdata = test_x)
    
    test_y <- test_y
    covered <- (test_y >= test_TIlower) & (test_y <= test_TIupper)
    widths <- TI_upper - TI_lower
    MPIW <- mean(widths)
    PICP <- mean(covered)
    NMPIW <- MPIW / (max(test_y) - min(test_y))
    
    time_elapsed <- as.numeric(difftime(Sys.time(), start_time, units = "secs"))
    
    cat(sprintf("  âœ… Seed %d ì™„ë£Œ - PICP: %.4f, NMPIW: %.4f, ì‹œê°„: %.2f ì´ˆ\n", s, PICP, NMPIW, time_elapsed))
    picp_list <- c(picp_list, PICP); nmpiw_list <- c(nmpiw_list, NMPIW); time_list <- c(time_list, time_elapsed)
  }
  
  results_summary_hoeffding <- rbind(results_summary_hoeffding, data.frame(
    x1 = x1_name, x2 = x2_name, x3 = x3_name,
    mean_PICP = mean(picp_list),
    mean_NMPIW = trimmed_mean(nmpiw_list),
    mean_time = mean(time_list)
  ))
  
  
  cat(sprintf("ðŸŸ¢ ì¡°í•© ì™„ë£Œ: %s + %s + %s â†’ í‰ê·  PICP: %.4f | trimmed NMPIW: %.4f | í‰ê·  ì‹œê°„: %.2fì´ˆ\n",
              x1_name, x2_name, x3_name,
              mean(picp_list), trimmed_mean(nmpiw_list), mean(time_list)))
}


library(ggplot2)
library(dplyr)
results_summary_hoeffding %>% 
  mutate(across(c('mean_PICP','mean_NMPIW'), 
                ~format(round(.x, 4), scientific = FALSE)))
