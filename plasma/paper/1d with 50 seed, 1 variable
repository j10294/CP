#-----------------------------------------------------------# 필요한 함수 ##
# 벡터의 L2 norm 계산 함수
compute_norm <- function(vector) {
  return(sqrt(sum(vector^2)))
}

# 확률 계산 함수 (Prop 3.1 내부)
compute_probability <- function(nu, t, P, k, norm_lx_h) {
  tryCatch({
    q_val <- qchisq(P, df = 1, ncp = t^2) #qchisq value 설정
    lhs <- q_val / ((t * sqrt(5 / nu)) + 1) #이 값이 k^2보다 크면, probability가 0으로 감.
    
    if (lhs <= k^2) {
      threshold <- (nu * q_val) / (k^2)
      probability <- pchisq(threshold, df = nu, lower.tail = FALSE) #probability term
      
      if (is.na(probability) || is.nan(probability)) return(1e-6)
      return(probability)
    } else {
      return(0) #이 값이 k^2보다 크면, probability가 0으로 감.
    }
  }, error = function(e) {
    warning("compute_probability 계산 오류 발생")
    return(0)
  })
}


# 적분 함수
integrand <- function(t, k, nu, P, norm_lx_h) {
  exp_term <- exp(-t^2 / (2 * norm_lx_h^2))
  if (exp_term < 1e-5) return(0) #exp term 이 너무 작으면 그냥 0 반환
  
  prob_term <- compute_probability(nu, t, P, k, norm_lx_h)
  return(exp_term * prob_term)
}

find_upper_bound_t <- function(k, nu, P) {
  t_seq <- seq(0.01, 100, by = 0.05)  # 탐색 구간
  valid_t <- sapply(t_seq, function(t) {
    q_val <- qchisq(P, df = 1, ncp = t^2)
    lhs <- q_val / ((t * sqrt(5 / nu)) + 1)
    return(lhs <= k^2)
  })
  
  if (any(valid_t)) {
    return(max(t_seq[valid_t]))
  } else {
    warning("조건을 만족하는 t가 없음 — fallback to t = 10")
    return(10)
  }
}

# k-factor 계산 함수
find_k_factor <- function(nu, norm_lx_h, P = 0.90, gamma = 0.95, index = NA) {
  start_time <- Sys.time()
  cat("▶️ k-factor 계산 시작: index =", index, "\n")
  
  obj_func <- function(k) {
    upper_bound <- find_upper_bound_t(k, nu, P)
    
    if (is.na(upper_bound) || is.infinite(upper_bound) || upper_bound < 1e-6) {
      warning("upper_bound가 이상함 → fallback")
      return(Inf) #upperbound 상한값을 inf로 설정
    }
    
    result <- tryCatch({
      integral_result <- integrate(integrand, lower = 0, upper = upper_bound,
                                   k = k, nu = nu, P = P, norm_lx_h = norm_lx_h)$value
      if (is.na(integral_result) || is.nan(integral_result)) return(Inf)
      pi_term <- sqrt(2 / (pi * norm_lx_h^2))
      error <- abs((pi_term * integral_result) - gamma)
      
      cat("  ⏳ k =", round(k, 5), 
          ", upper bound of t ", upper_bound, 
          ", integral =", round(pi_term * integral_result, 5), 
          ", error =", round(error, 5), "\n")
      
    }, error = function(e) {
      warning("적분 실패")
      return(Inf)
    })
    
    return(result)
  }
  
  
  tryCatch({
    return(optimize(obj_func, interval = c(0.01, 5), tol = 1e-2)$minimum)
    elapsed <- Sys.time() - start_time
    cat("✅ index =", index, ", 최적 k =", round(out, 5), ", 시간:", round(elapsed, 2), "초\n")
    
  }, error = function(e) {
    warning("k 최적화 실패")
    return(sqrt(nu*qchisq(p=0.90, df=1, ncp=norm_lx_h^2)/qchisq(p=1-gamma, df=nu, ncp=0))) # 최적화 실패 시 근사값 사용
  })
}

#-----------------------------------------------------------# 필요한 함수 ##




library(splines)
library(gam)
library(MASS)
library(parallel)

# 시드 반복
seeds <- 1:50
picp_list <- numeric(length(seeds))
nmpiw_list <- numeric(length(seeds))
getwd()
for (s in seeds) {
  cat("▶️ Seed", s, "계산 시작...\n")
  start_time <- Sys.time()
  
  # ----- 데이터 준비 및 정제 -----
  data <- read.csv("~/Downloads/plasma.csv")
  x <- data$AGE
  y <- data$CALORIES
  
  clean_data <- function(x, y) {
    idx <- which(!is.na(x) & !is.na(y) & !is.infinite(x) & !is.infinite(y))
    return(list(x = x[idx], y = y[idx]))
  }
  
  set.seed(s)
  m <- length(y)
  n_test <- 115
  n_train <- m - n_test
  idx <- sample(seq_len(m))
  train_idx <- idx[1:n_train]
  test_idx <- idx[(n_train+1):m]
  
  train_x <- x[train_idx]
  raw_train_y <- y[train_idx]
  test_x <- x[test_idx]
  raw_test_y <- y[test_idx]
  
  train_clean <- clean_data(train_x, raw_train_y)
  cat("Seed", s, ": transform 후 usable obs =", length(train_x), "\n")
  train_x <- train_clean$x
  raw_train_y <- train_clean$y
  
  # 평균 및 분산 추정
  raw_fit <- smooth.spline(train_x, raw_train_y, cv = FALSE)
  raw_pred_y <- predict(raw_fit, train_x)$y
  raw_residuals <- raw_train_y - raw_pred_y
  fit_var <- gam(raw_residuals^2 ~ s(train_x), family = Gamma(link = "log"))
  var_list <- predict(fit_var, newdata = data.frame(train_x = train_x), type = "response")
  var_list <- pmax(var_list, 1e-4)
  transform_y <- raw_train_y / sqrt(var_list)
  
  transform_clean <- clean_data(train_x, transform_y)
  train_x <- transform_clean$x
  train_y <- transform_clean$y
  
  # 단일 분산 추정
  fit <- smooth.spline(train_x, train_y, cv = FALSE)
  residuals <- predict(fit, train_x)$y - train_y
  B <- bs(train_x, df = max(fit$df), 3)
  D <- diff(diag(ncol(B)), differences = 2)
  S_inv <- ginv(t(B) %*% B + fit$lambda * t(D) %*% D)
  smoother_matrix <- B %*% S_inv %*% t(B)
  I_n <- diag(length(train_x))
  residual_matrix <- I_n - smoother_matrix
  
  estimated_variance <- (t(residuals) %*% residuals) / (sum(diag(t(residual_matrix) %*% residual_matrix)))
  
  # nu 계산 
  numerator <- sum(diag(t(residual_matrix) %*% residual_matrix))^2
  denominator <- sum(diag((t(residual_matrix) %*% residual_matrix)^2))
  nu <- numerator / denominator
  
  ### k factor 계산 ###
  # 1. smoothing vector의 norm 계산
  norm_lx_h_values <- apply(smoother_matrix, 2, compute_norm)
  rounded_nlh <- round(norm_lx_h_values, 5)  # float 오차 방지용
  
  # 2. 첫 번째 시드에 대해서만 k-factor 계산
  if (s == 1) {
    unique_nlh <- sort(unique(rounded_nlh))
    k_lookup <- mclapply(unique_nlh, function(nlh) {
      find_k_factor(nu = nu, norm_lx_h = nlh)
    }, mc.cores = detectCores() - 1)
    names(k_lookup) <- unique_nlh
    saveRDS(k_lookup, "k_lookup_saved.rds")
  } else {
    k_lookup <- readRDS("k_lookup_saved.rds")
    missing_nlh <- setdiff(unique(rounded_nlh), names(k_lookup))
    if (length(missing_nlh) > 0) {
      cat("⚠️ 누락된 k-factor 계산:", length(missing_nlh), "개\n") #앞 시드에서 계산되지 않은x값들에 대한 k factor는 추가적으로 계산해서 k_lookup에 누적 저장
      new_k <- mclapply(missing_nlh, function(nlh) {
        find_k_factor(nu = nu, norm_lx_h = as.numeric(nlh))
      }, mc.cores = detectCores() - 1)
      names(new_k) <- missing_nlh
      k_lookup <- c(k_lookup, new_k)
      saveRDS(k_lookup, "k_lookup_saved.rds")
    }
  }
  
  k_factors <- as.numeric(unlist(k_lookup[as.character(rounded_nlh)]))
  pred_y <- predict(fit, train_x)$y
  TI_upper <- pred_y + k_factors * as.numeric(estimated_variance)
  TI_lower <- pred_y - k_factors * as.numeric(estimated_variance)
  raw_TI_upper <- TI_upper * sqrt(var_list)
  raw_TI_lower <- TI_lower * sqrt(var_list)
  
  cat("✅ Seed", s, ": raw_TI_lower NA 수 =", sum(is.na(raw_TI_lower)), "\n")
  cat("✅ Seed", s, ": train_x NA 수 =", sum(is.na(train_x)), "\n")
  
  TI_lower_df <- aggregate(raw_TI_lower ~ train_x, FUN = mean)
  TI_upper_df <- aggregate(raw_TI_upper ~ train_x, FUN = mean)
  interp_lower <- approx(x = TI_lower_df$train_x, y = TI_lower_df$raw_TI_lower, xout = test_x)$y
  interp_upper <- approx(x = TI_upper_df$train_x, y = TI_upper_df$raw_TI_upper, xout = test_x)$y
  
  included <- (raw_test_y >= interp_lower) & (raw_test_y <= interp_upper)
  picp <- mean(included, na.rm = TRUE)
  nmpiw <- mean(interp_upper - interp_lower, na.rm = TRUE) / (max(raw_test_y) - min(raw_test_y))
  
  picp_list[s] <- picp
  nmpiw_list[s] <- nmpiw
  
  end_time <- Sys.time()
  cat("✅ Seed", s, "완료 - PICP:", round(picp, 4), "NMPIW:", round(nmpiw, 4),
      "| 소요시간:", round(as.numeric(end_time - start_time, units = "secs"), 2), "초\n\n")
}

cat("📌 전체 평균 PICP:", round(mean(picp_list), 4), "\n")
cat("📌 전체 평균 NMPIW:", round(mean(nmpiw_list), 4), "\n")
