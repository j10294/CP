#-----------------------------------------------------------# 필요한 함수 ##
# 벡터의 L2 norm 계산 함수
compute_norm <- function(vector) {
  return(sqrt(sum(vector^2)))
}

# 확률 계산 함수 (Prop 3.1 내부)
compute_probability <- function(nu, t, P, k, norm_lx_h) {
  tryCatch({
    q_val <- suppressWarnings(qchisq(P, df = 1, ncp = t^2))
    if (is.na(q_val) || is.nan(q_val) || is.infinite(q_val)) return(1e-6)
    
    lhs <- q_val / ((t * sqrt(5 / nu)) + 1)
    if (lhs <= k^2) {
      threshold <- (nu * q_val) / (k^2)
      prob <- suppressWarnings(pchisq(threshold, df = nu, lower.tail = FALSE))
      if (is.na(prob) || is.nan(prob) || is.infinite(prob)) return(1e-6)
      return(prob)
    } else {
      return(0)
    }
  }, error = function(e) {
    warning("compute_probability 계산 오류 발생")
    return(1e-6)
  })
}


# 적분 함수
integrand <- function(t, k, nu, P, norm_lx_h) {
  # exp_term 계산
  exp_term <- exp(-t^2 / (2 * norm_lx_h^2))
  exp_term[is.nan(exp_term) | is.infinite(exp_term) | exp_term < 1e-10] <- 0
  
  # prob_term 계산 (벡터 t에 대해 반복 적용)
  prob_term <- sapply(t, function(ti) {
    compute_probability(nu, ti, P, k, norm_lx_h)
  })
  
  # 결합 및 방어
  result <- exp_term * prob_term
  result[is.nan(result) | is.infinite(result)] <- 0
  return(result)
}



find_upper_bound_t <- function(k, nu, P) {
  t_seq <- seq(0.01, 20, by = 0.01)  # 너무 큰 t는 제거 (적분 범위가 커져서 실패 위험 높아짐)
  
  for (t in t_seq) {
    q_val <- suppressWarnings(qchisq(P, df = 1, ncp = t^2))
    if (is.na(q_val) || is.nan(q_val) || is.infinite(q_val)) next
    
    lhs <- q_val / ((t * sqrt(5 / nu)) + 1)
    if (!is.na(lhs) && lhs <= k^2) {
      return(t)  # 조건 만족하는 최소의 t 반환
    }
  }
  
  warning("❌ 조건 만족하는 t를 찾지 못했음 — fallback to t = 10")
  return(10)
}



# k-factor 계산 함수
find_k_factor <- function(nu, norm_lx_h, P = 0.90, gamma = 0.95, index = NA) {
  obj_func <- function(k) {
    upper_bound <- find_upper_bound_t(k, nu, P)
    if (is.na(upper_bound) || is.infinite(upper_bound) || upper_bound < 1e-6) return(NA)
    
    result <- tryCatch({
      integral_result <- integrate(integrand, lower = 0, upper = upper_bound,
                                   k = k, nu = nu, P = P, norm_lx_h = norm_lx_h)$value
      if (is.na(integral_result) || is.nan(integral_result)) return(NA)
      pi_term <- sqrt(2 / (pi * norm_lx_h^2))
      error <- abs((pi_term * integral_result) - gamma)
      return(error)
    }, error = function(e) NA)
    
    return(result)
  }
  
  opt_result <- tryCatch({
    optimize(obj_func, interval = c(0.01, 5), tol = 1e-2)
  }, error = function(e) NULL)
  
  if (!is.null(opt_result) &&
      is.list(opt_result) &&
      is.numeric(opt_result$objective) &&
      !is.na(opt_result$objective) &&
      is.finite(opt_result$objective)) {
    return(list(k = opt_result$minimum, fallback = FALSE))
  } else {
    approx_k <- sqrt(nu * qchisq(p = P, df = 1, ncp = norm_lx_h^2) /
                       qchisq(p = 1 - gamma, df = nu, ncp = 0))
    return(list(k = approx_k, fallback = TRUE))
  }
}



#-----------------------------------------------------------# 필요한 함수 ##

library(mgcv)
library(fields)
library(MASS)

# 데이터 로드
data <- read.csv("/Users/hdmt306/Downloads/plasma.csv")
x1 <- data$BETAPLASMA
x2 <- data$FAT
y <- data$RETPLASMA

# 결과 저장용 리스트
results <- list()

# 반복: 시드 1~50
for (s in 1:50) {
  start_time <- Sys.time()
  set.seed(s)
  m <- length(y)
  n_test <- 115
  n_train <- m - n_test
  
  idx <- sample(seq_len(m))
  train_idx <- idx[1:n_train]
  test_idx <- idx[(n_train+1):m]
  
  train_x <- data.frame(x1 = x1[train_idx], x2 = x2[train_idx])
  raw_train_y <- y[train_idx]
  test_x <- data.frame(x1 = x1[test_idx], x2 = x2[test_idx])
  raw_test_y <- y[test_idx]
  
  # 평균 추정
  raw_fit <- gam(raw_train_y ~ te(train_x$x1, train_x$x2))
  raw_pred_y <- predict(raw_fit, train_x = train_x)
  raw_residuals <- raw_train_y - raw_pred_y
  
  # 분산 추정
  log_res2 <- log(raw_residuals^2 + 1e-8)
  variance_fit <- gam(log_res2 ~ te(train_x$x1, train_x$x2))
  var_list <- exp(predict(variance_fit, train_x = train_x))
  
  # 정규화된 y
  train_y <- raw_train_y / sqrt(var_list)
  
  # 평활 추정
  fit <- gam(train_y ~ te(train_x$x1, train_x$x2))
  residuals <- train_y - predict(fit, train_x = train_x)
  
  B <- predict(fit, type = 'lpmatrix')
  lambda <- fit$sp[1]
  D <- diff(diag(ncol(B)), differences = 2)
  S_inv <- ginv(t(B) %*% B + lambda * t(D) %*% D)
  S <- B %*% S_inv %*% t(B)
  I_n <- diag(nrow(S))
  residual_matrix <- I_n - S
  
  estimated_variance <- as.numeric((t(residuals) %*% residuals) / sum(diag(t(residual_matrix) %*% residual_matrix)))
  
  # 자유도 추정
  numerator <- sum(diag(t(residual_matrix) %*% residual_matrix))^2
  denominator <- sum(diag((t(residual_matrix) %*% residual_matrix)^2))
  nu <- numerator / denominator
  
  # norm 계산
  norm_lx_h_values <- apply(S, 2, compute_norm)
  
  # k-factor 계산 (근사 사용했는지 여부 추가)
  k_results <- mapply(function(nlh, i) {
    result <- find_k_factor(nu = nu, norm_lx_h = nlh, index = i)
    return(result)
  }, norm_lx_h_values, seq_along(norm_lx_h_values), SIMPLIFY = FALSE)
  
  k_factors <- sapply(k_results, function(res) res$k)
  fallback_flags <- sapply(k_results, function(res) res$fallback)
  num_fallbacks <- sum(fallback_flags)
  
  
  # TI 계산
  pred_y <- predict(fit, train_x = train_x)
  TI_upper <- pred_y + k_factors * estimated_variance
  TI_lower <- pred_y - k_factors * estimated_variance
  
  # 원래 단위로 변환
  raw_TI_upper <- TI_upper * sqrt(var_list)
  raw_TI_lower <- TI_lower * sqrt(var_list)
  
  # 선형보간
  # Tps 경고 메시지 제거용 sink
  sink(tempfile())  # 콘솔 출력을 임시 파일로 보냄
  tps_lower <- Tps(x = as.matrix(train_x), Y = raw_TI_lower)
  tps_upper <- Tps(x = as.matrix(train_x), Y = raw_TI_upper)
  sink()  # 콘솔 출력을 원래대로 복구
  
  
  test_TIlower <- predict(tps_lower, x = as.matrix(test_x))
  test_TIupper <- predict(tps_upper, x = as.matrix(test_x))
  
  # 평가 지표
  test_y <- raw_test_y
  covered <- (test_y >= test_TIlower) & (test_y <= test_TIupper)
  widths <- raw_TI_upper - raw_TI_lower
  MPIW <- mean(widths)
  PICP <- mean(covered)
  NMPIW <- MPIW / (max(test_y) - min(test_y))
  
  results[[s]] <- data.frame(seed = s, PICP = PICP, NMPIW = NMPIW)
  
  elapsed <- Sys.time() - start_time
  cat(sprintf("✅ Seed %d 완료 - PICP: %.4f, NMPIW: %.4f | 소요시간: %.2f 초 | fallback k: %d개\n",
              s, PICP, NMPIW, as.numeric(elapsed, units = "secs"), num_fallbacks))
  
}

# 결과 통합
results_df <- do.call(rbind, results)
results_df




######## 모든 조합 ##########
library(mgcv)
library(fields)
library(MASS)


# 데이터 불러오기
data <- read.csv("/Users/hdmt306/Downloads/plasma.csv")

# 변수 목록
all_vars <- c("BETADIET", "CALORIES", "CHOLESTEROL", "FAT", 
              "FIBER", "QUETELET", "RETDIET", "AGE")
target_y <- data$BETAPLASMA

# 결과 저장
results_summary <- data.frame()

# 변수 조합 생성 (중복, 자기 자신 제외)
var_combinations <- combn(all_vars, 2, simplify = FALSE)

# 반복
for (vars in var_combinations) {
  x1_name <- vars[1]
  x2_name <- vars[2]
  
  cat(sprintf("\n🔧 현재 조합: x1 = %s, x2 = %s\n", x1_name, x2_name))
  
  picp_list <- c()
  nmpiw_list <- c()
  time_list <- c()
  fallback_count_list <- c()
  
  for (s in 1:50) {
    cat(sprintf("  ▶️ Seed %d 시작...\n", s))
    
    start_time <- Sys.time()
    set.seed(s)
    
    x1 <- data[[x1_name]]
    x2 <- data[[x2_name]]
    y <- target_y
    
    # 결측 제거
    complete_idx <- complete.cases(x1, x2, y)
    x1 <- x1[complete_idx]; x2 <- x2[complete_idx]; y <- y[complete_idx]
    
    m <- length(y)
    n_test <- 115
    n_train <- m - n_test
    
    idx <- sample(seq_len(m))
    train_idx <- idx[1:n_train]
    test_idx <- idx[(n_train + 1):m]
    
    train_x <- data.frame(x1 = x1[train_idx], x2 = x2[train_idx])
    raw_train_y <- y[train_idx]
    test_x <- data.frame(x1 = x1[test_idx], x2 = x2[test_idx])
    raw_test_y <- y[test_idx]
    
    # 평균 추정
    raw_fit <- gam(raw_train_y ~ te(x1, x2), data = train_x)
    raw_pred_y <- predict(raw_fit, train_x = train_x)
    raw_residuals <- raw_train_y - raw_pred_y
    
    # 분산 추정
    log_res2 <- log(raw_residuals^2 + 1e-8)
    variance_fit <- gam(log_res2 ~ te(x1, x2), data = train_x)
    var_list <- exp(predict(variance_fit, train_x = train_x))
    train_y <- raw_train_y / sqrt(var_list)
    
    # 평활 추정
    fit <- gam(train_y ~ te(x1, x2), data = train_x)
    residuals <- train_y - predict(fit, train_x = train_x)
    B <- predict(fit, type = "lpmatrix")
    lambda <- fit$sp[1]
    D <- diff(diag(ncol(B)), differences = 2)
    S_inv <- ginv(t(B) %*% B + lambda * t(D) %*% D)
    S <- B %*% S_inv %*% t(B)
    I_n <- diag(nrow(S))
    residual_matrix <- I_n - S
    
    estimated_variance <- as.numeric((t(residuals) %*% residuals) / sum(diag(t(residual_matrix) %*% residual_matrix)))
    
    numerator <- sum(diag(t(residual_matrix) %*% residual_matrix))^2
    denominator <- sum(diag((t(residual_matrix) %*% residual_matrix)^2))
    nu <- numerator / denominator
    norm_lx_h_values <- apply(S, 1, function(v) sqrt(sum(v^2)))
    
    # k-factor 계산
    fallback_flags <- c()
    k_factors <- sapply(norm_lx_h_values, function(nlh) {
      result <- find_k_factor(nu = nu, norm_lx_h = nlh)
      fallback_flags <<- c(fallback_flags, result$fallback)
      return(result$k)
    })
    
    pred_y <- predict(fit, train_x = train_x)
    TI_upper <- pred_y + k_factors * estimated_variance
    TI_lower <- pred_y - k_factors * estimated_variance
    raw_TI_upper <- TI_upper * sqrt(var_list)
    raw_TI_lower <- TI_lower * sqrt(var_list)
    
    # 선형보간
    sink(tempfile())
    tps_lower <- Tps(x = as.matrix(train_x), Y = raw_TI_lower)
    tps_upper <- Tps(x = as.matrix(train_x), Y = raw_TI_upper)
    sink()
    
    test_TIlower <- predict(tps_lower, x = as.matrix(test_x))
    test_TIupper <- predict(tps_upper, x = as.matrix(test_x))
    
    test_y <- raw_test_y
    covered <- (test_y >= test_TIlower) & (test_y <= test_TIupper)
    widths <- raw_TI_upper - raw_TI_lower
    MPIW <- mean(widths)
    PICP <- mean(covered)
    NMPIW <- MPIW / (max(test_y) - min(test_y))
    
    end_time <- Sys.time()
    time_elapsed <- as.numeric(end_time - start_time, units = "secs")
    
    cat(sprintf("  ✅ Seed %d 완료 - PICP: %.4f, NMPIW: %.4f, fallback k: %d, 시간: %.2f 초\n",
               s, PICP, NMPIW, sum(fallback_flags), time_elapsed))
    picp_list <- c(picp_list, PICP)
    nmpiw_list <- c(nmpiw_list, NMPIW)
    time_list <- c(time_list, time_elapsed)
    fallback_count_list <- c(fallback_count_list, sum(fallback_flags))
  }
  
  # 평균값 저장
  results_summary <- rbind(results_summary, data.frame(
    x1 = x1_name,
    x2 = x2_name,
    mean_PICP = mean(picp_list),
    mean_NMPIW = mean(nmpiw_list),
    mean_time = mean(time_list),
    total_fallbacks = sum(fallback_count_list),
    mean_fallbacks_per_run = mean(fallback_count_list)
  ))
  
  cat(sprintf("🟢 조합 완료: %s + %s → 평균 PICP: %.4f | 평균 NMPIW: %.4f | 평균 시간: %.2f초 | 총 fallback: %d개\n",
              x1_name, x2_name, mean(picp_list), mean(nmpiw_list), mean(time_list), sum(fallback_count_list)))
  
}

results_summary

