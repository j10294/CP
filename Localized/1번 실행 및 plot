library(splines)
library(mgcv)
library(MASS)

# --- 데이터 생성 ---
set.seed(123)
generate_data <- function(n = 2000) {
  x <- runif(n = n, min = -5, max = 5)
  y <- ifelse(abs(x) <= 4.5, cos(pi * x / 10) * rnorm(n, 0, 1), 
              2 * rnorm(n, 0, 1))
  return(data.frame(x = x, y = y))
}

# --- Truth Tolerance Interval ---
compute_truth_interval <- function(x_seq) {
  sd_vals <- ifelse(abs(x_seq) <= 4.5, abs(cos(pi * x_seq / 10)), 2)
  list(lower = -1.645 * sd_vals, upper = 1.645 * sd_vals)
}

# --- Ours 방법 λ 계산 ---
find_lambda_hat <- function(alpha, delta, y, pred, variance, n,
                            lower = 0, upper = 30, step = 1e-3) {
  
  threshold <- alpha - sqrt(log(1/delta) / (2*n))
  threshold <- max(0, threshold) #truncation
  
  lambda_seq <- seq(lower, upper, by = step)
  
  for (lambda in lambda_seq) {
    # empirical risk 계산
    risk <- mean(
      y <= pred - sqrt(variance) * lambda |
        y >= pred + sqrt(variance) * lambda,
      na.rm = TRUE
    )
    
    # 조건을 만족하는 가장 첫 λ 반환
    if (risk <= threshold) {
      return(lambda)
    }
  }
  
  # 조건 만족하는 lambda가 없을 경우
  return(NA)
}

find_lambda_hat_weighted <- function(alpha, delta, y, pred, variance, n,
                                     lower = 0, upper = 30, step = 1e-3,
                                     weights = NULL) {
  threshold <- alpha - sqrt(log(1 / delta) / (2 * n))
  threshold <- max(0, threshold)
  
  lambda_seq <- seq(lower, upper, by = step)
  
  for (lambda in lambda_seq) {
    indicator <- (y <= pred - sqrt(variance) * lambda |
                    y >= pred + sqrt(variance) * lambda)
    
    risk <- if (is.null(weights)) {
      mean(indicator, na.rm = TRUE)
    } else {
      weights <- weights / sum(weights, na.rm = TRUE)
      sum(weights * indicator, na.rm = TRUE)
    }
    
    if (risk <= threshold) return(lambda)
  }
  return(NA)
}

find_lambda_hat_asym<- function(alpha, delta, y, pred, variance, n,
                                            lower = 0, upper = 30, step = 1e-3,
                                            weights = NULL,
                                            max_iter = 5, damping = 0.5) {
  threshold <- alpha - sqrt(log(1 / delta) / (2 * n))
  threshold <- max(0, threshold)
  
  compute_risk <- function(lambda_1, lambda_2) {
    indicator <- (y <= pred - sqrt(variance) * lambda_1 |
                    y >= pred + sqrt(variance) * lambda_2)
    if (is.null(weights)) {
      mean(indicator, na.rm = TRUE)
    } else {
      w <- weights / sum(weights, na.rm = TRUE)
      sum(w * indicator, na.rm = TRUE)
    }
  }
  
  binary_search <- function(lambda_fixed, side = c("lower", "upper")) {
    side <- match.arg(side)
    l <- lower
    u <- upper
    while ((u - l) > step) {
      mid <- (l + u) / 2
      risk <- if (side == "lower") compute_risk(mid, lambda_fixed)
      else compute_risk(lambda_fixed, mid)
      if (risk > threshold) {
        l <- mid
      } else {
        u <- mid
      }
    }
    return((l + u) / 2)
  }
  
  # 초기값
  lambda_1 <- upper / 2
  lambda_2 <- upper / 2
  
  for (i in 1:max_iter) {
    new_lambda_1 <- binary_search(lambda_2, side = "lower")
    lambda_1 <- damping * new_lambda_1 + (1 - damping) * lambda_1
    
    new_lambda_2 <- binary_search(lambda_1, side = "upper")
    lambda_2 <- damping * new_lambda_2 + (1 - damping) * lambda_2
  }
  
  return(c(lambda_1, lambda_2))
}


# --- weight 계산 (Gaussian / Exponential / NABC) ---
compute_weights <- function(x_cal, x0,
                            h0 = 0.5, target_eff = 50, max_h = 3,
                            kernel = c("gaussian", "exponential")) {
  kernel <- match.arg(kernel)
  dist <- abs(x_cal - x0)
  h <- h0
  
  repeat {
    w_raw <- if (kernel == "gaussian") {
      exp(-dist^2 / h^2)
    }  else {
      exp(-dist / h)
    }
    
    w <- w_raw / sum(w_raw)
    n_eff <- 1 / sum(w^2)
    
    if (n_eff >= target_eff || h >= max_h) break
    h <- h * 1.5
  }
  
  return(w)
}

# --- GY 방법 관련 함수들 ---
compute_norm <- function(vector) sqrt(sum(vector^2))

compute_probability <- function(nu, t, P, k, norm_lx_h) {
  tryCatch({
    q_val <- qchisq(P, df = 1, ncp = pmin(1e4,t^2))
    out <- numeric(length(q_val))
    for (i in seq_along(q_val)) {
      q <- q_val[i]
      if (is.nan(q) || is.na(q)) { out[i] <- 0; next }
      threshold <- (nu * q) / (k^2)
      prob <- pchisq(threshold, df = nu, lower.tail = FALSE)
      out[i] <- ifelse(is.nan(prob) || is.na(prob), 1e-6, prob)
    }
    return(out)
  }, error = function(e) rep(0, length(t)))
} #prop 3.1 의 Pr부분 계산하는 함수. t값을 받아 확률을 계산함 

integrand <- function(t, k, nu, P, norm_lx_h) {
  exp_term <- exp(-t^2 / (2 * norm_lx_h^2))
  prob_term <- compute_probability(nu, t, P, k, norm_lx_h)
  if (log(exp_term) < -20) return(1e-3) #너무 작으면 -inf이 나오므로 이부분 방지
  return(exp_term * prob_term)
}

find_k_factor <- function(nu, norm_lx_h, P = 0.90, gamma = 0.95, tol=1e-2) {
  obj_func <- function(k) {
    
    integral_result <- tryCatch({
      integrate(Vectorize(integrand), lower = 0, upper = 30,
                k = k, nu = nu, P = P, norm_lx_h = norm_lx_h)$value
    }, error = function(e) NA)
    
    if (is.na(integral_result)) {
      warning(sprintf('적분 실패 for k=%.3f', k))
      return(NA)
    }
    
    pi_term <- sqrt(2 / (pi * norm_lx_h^2))
    final_val <- pi_term * integral_result
    abs(final_val - gamma)
  }
  
  k_vals <- seq(0.01, 10, length.out = 1000)
  obj_vals <- sapply(k_vals, obj_func)
  
  if (all(is.na(obj_vals))) {
    warning('All objective values are NA')
    return(NA)
  }
  
  k_best <- k_vals[which.min(obj_vals)]
  return(k_best)
}

# --- 데이터 생성 및 샘플링 ---
set.seed(123)
data <- generate_data()
m <- nrow(data)
n_train <- m / 2
n_cal <- m / 2
alpha <- 0.10
delta <- 0.05

all_indices <- sample(m)
train_index <- all_indices[1:n_train]
cal_index <- all_indices[(n_train + 1):m]

train_x <- data$x[train_index]
train_y <- data$y[train_index]
cal_x <- data$x[cal_index]
cal_y <- data$y[cal_index]

# --- Spline 학습 및 분산 추정 (calibration 기반) ---
fit <- smooth.spline(x = train_x, y = train_y, cv = FALSE)
pred_y_cal <- predict(fit, cal_x)$y
residuals_cal <- cal_y - pred_y_cal
log_res2 <- log(residuals_cal^2 + 1e-6)
gam_model <- gam(log_res2 ~ s(cal_x))
variance_hat <- exp(predict(gam_model, newdata = data.frame(cal_x = cal_x)))

# ours 방법 계산 (Gaussian / Exponential)
alpha <- 0.10
delta <- 0.05
x_seq <- sort(cal_x)

lambda_gaussian <- sapply(x_seq, function(x0) {
  w <- compute_weights(cal_x, x0, kernel = "gaussian")
  pred <- predict(fit, x0)$y
  var_hat <- exp(predict(gam_model, newdata = data.frame(cal_x = x0)))
  find_lambda_hat_weighted(alpha, delta, cal_y, rep(pred, length(cal_y)),
                           rep(var_hat, length(cal_y)), length(cal_y), weights = w)
})

lambda_gaussian_asym <- sapply(x_seq, function(x0) {
  w <- compute_weights(cal_x, x0, kernel = "gaussian")
  pred <- predict(fit, x0)$y
  var_hat <- exp(predict(gam_model, newdata = data.frame(cal_x = x0)))
  find_lambda_hat_asym(alpha, delta, cal_y, rep(pred, length(cal_y)),
                           rep(var_hat, length(cal_y)), length(cal_y), weights = w)
})

  
lambda_exponential <- sapply(x_seq, function(x0) {
  w <- compute_weights(cal_x, x0, kernel = "exponential")
  pred <- predict(fit, x0)$y
  var_hat <- exp(predict(gam_model, newdata = data.frame(cal_x = x0)))
  find_lambda_hat_weighted(alpha, delta, cal_y, rep(pred, length(cal_y)),
                           rep(var_hat, length(cal_y)), length(cal_y), weights = w)
})


lambda_exponential_asym <- sapply(x_seq, function(x0) {
  w <- compute_weights(cal_x, x0, kernel = "exponential")
  pred <- predict(fit, x0)$y
  var_hat <- exp(predict(gam_model, newdata = data.frame(cal_x = x0)))
  find_lambda_hat_asym(alpha, delta, cal_y, rep(pred, length(cal_y)),
                           rep(var_hat, length(cal_y)), length(cal_y), weights = w)
})




lambda_hat <- find_lambda_hat(alpha, delta, cal_y, pred_y_cal, variance_hat, n_cal)

pred_seq <- predict(fit, x_seq)$y
var_seq <- exp(predict(gam_model, newdata = data.frame(cal_x = x_seq)))

ours_upper_gaussian <- pred_seq + sqrt(var_seq) * lambda_gaussian
ours_lower_gaussian <- pred_seq - sqrt(var_seq) * lambda_gaussian

ours_upper_gaussian_asym <- pred_seq + sqrt(var_seq) * lambda_gaussian_asym[2,]
ours_lower_gaussian_asym <- pred_seq - sqrt(var_seq) * lambda_gaussian_asym[1,]

ours_upper_exponential <- pred_seq + sqrt(var_seq) * lambda_exponential
ours_lower_exponential <- pred_seq - sqrt(var_seq) * lambda_exponential

ours_upper_exponential_asym <- pred_seq + sqrt(var_seq) * lambda_exponential_asym[2,]
ours_lower_exponential_asym <- pred_seq - sqrt(var_seq) * lambda_exponential_asym[1,]

ours_upper <- pred_seq + sqrt(var_seq)* lambda_hat
ours_lower <- pred_seq - sqrt(var_seq) * lambda_hat



# --- Truth 계산 ---
truth <- compute_truth_interval(x_seq)
truth_lower <- truth$lower
truth_upper <- truth$upper

# --- GY 방법 tolerance interval 계산 (transformation function 이용) ---
x <- data$x
y <- data$y
residuals <- y - predict(fit, x)$y
log_variance_fit <- smooth.spline(x, log(residuals^2 + 1e-6), cv = FALSE)
variance_hat <- exp(predict(log_variance_fit, x)$y)

transform_y <- y / sqrt(variance_hat)
fit_trans <- smooth.spline(x, transform_y, cv = FALSE)

B <- bs(x, df = fit_trans$df)
D <- diff(diag(ncol(B)), differences = 2)
S_inv <- ginv(t(B) %*% B + fit_trans$lambda * t(D) %*% D)
S <- B %*% S_inv %*% t(B)
I_n <- diag(length(x))
R <- I_n - S

residuals2 <- transform_y - predict(fit_trans, x)$y
est_var <- (t(residuals2) %*% residuals2) / sum(diag(t(R) %*% R))
num <- sum(diag(t(R) %*% R))^2
den <- sum(diag((t(R) %*% R)^2))
nu <- num / den

norm_lx_h_values <- sapply(1:ncol(S), function(j) compute_norm(S[, j]))

# k-factor 계산
k_factors <- sapply(norm_lx_h_values, function(nlh) {
  k <- find_k_factor(nu, nlh)
  if (is.na(k)) find_k_factor(nu, nlh) else k
})

# k_factors == 0.01인 부분은 평균으로 처리
idx <- which(k_factors == 0.01)
mean_k <- mean(k_factors[k_factors != 0.01], na.rm=TRUE); mean_k
k_factors[idx] <- mean_k

#전체 이용해서 gy interval 생성
pred_seq <- predict(fit_trans, x)$y
gy_upper <- ( pred_seq + sqrt(as.vector(est_var)) * k_factors ) * sqrt(variance_hat)
gy_lower <- ( pred_seq - sqrt(as.vector(est_var)) * k_factors ) * sqrt(variance_hat)




### 그래프 그리기 ###
library(ggplot2)

# 각각의 선을 label로 구분하기 위한 데이터 변환
library(tidyr)
library(dplyr)

# Ours 계열 선들을 long 형식으로 변환
df_long <- df_others %>%
  select(x,
         truth_lower, truth_upper,
         ours_lower, ours_upper,
         ours_lower_gaussian, ours_upper_gaussian,
         ours_lower_exponential, ours_upper_exponential) %>%
  pivot_longer(-x, names_to = "type", values_to = "y") %>%
  mutate(
    bound = ifelse(grepl("lower", type), "lower", "upper"),
    method = case_when(
      grepl("truth", type) ~ "Truth",
      grepl("ours_lower$|ours_upper$", type) ~ "Ours",
      grepl("gaussian", type) ~ "Ours (Gaussian)",
      grepl("exponential", type) ~ "Ours (Exponential)"
    )
  )

df_gy <- data.frame(
  x = data$x,
  y = data$y,
  gy_lower = gy_lower,
  gy_upper = gy_upper
)

# 시각화
# linetype은 aesthetic에 포함시키지 않고 색상만 범례로 사용
p <- ggplot() +
  # GY
  geom_point(data = df_gy, aes(x = x, y = y), color = "gray", size = 1, alpha = 0.5) +
  geom_ribbon(data = df_gy, aes(x = x, ymin = gy_lower, ymax = gy_upper),
              fill = "#CC79A7", alpha = 0.3) +
  
  # Truth
  geom_line(data = df_others, aes(x = x, y = truth_lower, color = "Truth"), size = 1) +
  geom_line(data = df_others, aes(x = x, y = truth_upper, color = "Truth"), size = 1) +
  
  # Ours
  geom_line(data = df_others, aes(x = x, y = ours_lower, color = "Ours"), size = 1) +
  geom_line(data = df_others, aes(x = x, y = ours_upper, color = "Ours"), size = 1) +
  
  # Ours (Gaussian)
  geom_line(data = df_others, aes(x = x, y = ours_lower_gaussian, color = "Ours (Gaussian)"), 
            size = 1, linetype = "dashed") +
  geom_line(data = df_others, aes(x = x, y = ours_upper_gaussian, color = "Ours (Gaussian)"), 
            size = 1, linetype = "dashed") +
  
  # Ours (Exponential)
  geom_line(data = df_others, aes(x = x, y = ours_lower_exponential, color = "Ours (Exponential)"), 
            size = 1, linetype = "twodash") +
  geom_line(data = df_others, aes(x = x, y = ours_upper_exponential, color = "Ours (Exponential)"), 
            size = 1, linetype = "twodash") +
  
  labs(title = "Tolerance Intervals: GY vs Ours vs Truth",
       x = "x", y = "y", color = "Method") +  # <--- color만 남김+
  theme(legend.position = "right") +
  theme_bw()+
  scale_color_manual(values = c(
    "Truth" = "black",
    "Ours" = "#E69F00",
    "Ours (Gaussian)" = "#56B4E9",
    "Ours (Exponential)" = "#CC79A7"
  ))


ggsave("0713_TI_비교.pdf", plot = p, width = 8, height = 5)

