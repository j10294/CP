#--------------------------------------------- 필요한 함수 정의
compute_local_q <- function(S, x_cal, x0, delta, alpha, h = 0.5) {
  dist <- abs(x_cal - x0)
  w_raw <- exp(-dist / h) #exponential kernel 수정 (0702)
  w <- w_raw / sum(w_raw)
  n_eff <- 1 / sum(w^2)
  
  epsilon <- sqrt(log(1 / alpha) / (2 * n_eff))
  threshold <- min(1, delta + epsilon)  # truncation
  
  S_sorted <- sort(S)
  S_order <- order(S)
  cum_weight <- cumsum(w[S_order])
  idx <- which(cum_weight >= threshold)[1]
  if (is.na(idx)) return(NA)
  return(S_sorted[idx])
}

#Na 발생 줄이는 함수 

# check n_eff 
compute_local_q_safe <- function(S, x_cal, x0, delta, alpha,
                                 h0 = 0.5, target_eff = 50, max_h = 3,
                                 record_env = NULL) {
  dist <- abs(x_cal - x0)
  h <- h0
  repeat {
    w_raw <- exp(-dist^2 / h^2)
    w <- w_raw / sum(w_raw)
    n_eff <- 1 / sum(w^2)
    if (n_eff >= target_eff || h >= max_h) break
    h <- h * 1.5
  }
  
  # 👉 기록
  if (!is.null(record_env)) {
    record_env$n_eff_list[[length(record_env$n_eff_list) + 1]] <- n_eff
    record_env$h_list[[length(record_env$h_list) + 1]] <- h
  }
  
  epsilon <- sqrt(log(1 / alpha) / (2 * n_eff))
  threshold <- min(1, delta + epsilon)
  
  if (n_eff < 3) {
    return(quantile(S, probs = delta, type = 1))
  }
  
  S_sorted <- sort(S)
  S_order <- order(S)
  cum_weight <- cumsum(w[S_order])
  idx <- which(cum_weight >= threshold)[1]
  
  if (is.na(idx)) {
    return(quantile(S, probs = delta, type = 1))
  }
  
  return(S_sorted[idx])
}

generate_data <- function(model, n) {
  #x <- sort(runif(n, 0, 10)) # x도 랜덤하게 생성
  x <- seq(0, 10, length.out=n)
  base <- 3 * cos(x) - 5 * (x / 15)^2
  
  if (model == 1) {
    y <- base + rnorm(n, mean = 0, sd = sqrt(2))
  }
  if (model == 2) {
    y <- base + rnorm(n, mean = 0, sd = sqrt(2 * x))
  }
  if (model == 3) {
    y <- base + 4 - rgamma(n, shape = 2, scale = 2)
  }
  if (model == 4) {
    y <- base + rt(n, df = 3)
  }
  if (model == 5) {
    sd_x <- 0.3 + 3 * exp(-(x - 5)^2 / (2 * 1.5^2))
    y <- base + rnorm(n, mean = 0, sd = sd_x)
  }
  if (model == 6) {
    y <- base + rnorm(n, mean = 0, sd = 1) + abs(rnorm(n, 0, 1)) - sqrt(2/pi)
  }
  if (model == 7) {
    noise <- ifelse(runif(n) < 0.5, rnorm(n, mean = -3, sd = 1), rnorm(n, mean = 3, sd = 1))
    y <- base + noise
  }
  if (model == 8) {
    noise <- ifelse(x < 5,
                    rnorm(n, mean = 0, sd = 1 + 0.5 * x),
                    rnorm(n, mean = 0, sd = 2 - 0.3 * (x - 5)))
    y <- base + noise
  }
  
  return(data.frame(x = x, y = y))
}

content_function <- function(model,lower,upper,x){
  y = 3*cos(x) - 5*(x/15)^2
  if (model == 1){
    content <- pnorm(upper-y, mean=0, sd=sqrt(2)) - pnorm(lower-y, mean=0, sd=sqrt(2)) #분산 2로 수정. guo and young model 1과 동일 
  }
  if (model == 2){
    content <- pnorm(upper-y, mean=0, sd=sqrt(2 * x)) - pnorm(lower-y, mean=0, sd=sqrt(2 * x))
  }
  if (model == 3){
    content <- pgamma(4 - (lower - y), shape = 2, scale = 2) -
      pgamma(4 - (upper - y), shape = 2, scale = 2)
  }
  if (model == 4){
    content <- pt(upper-y, df=3) - pt(lower-y, df=3)
  }
  if (model == 5){
    sd_x <- 0.3 + 3 * exp(-(x - 5)^2 / (2 * 1.5^2))
    content <- pnorm(upper-y, mean=0, sd=sd_x)- pnorm(lower-y, mean=0, sd=sd_x)
  }
  if (model == 6){
    #empirical content 계산 
    N <- 1e+5
    z1 <- rnorm(N, 0, 1)
    z2 <- abs(rnorm(N, 0, 1)) - sqrt(2 / pi)
    eps <- z1 + z2 #에러항 계산 후 
    content <- mean((eps >= lower - y) & (eps <= upper - y)) #에러항이 들어오는 평균을 content 로 계산 
  }
  
  if (model == 7) {
    N <- 1e+5
    u <- runif(N)
    eps <- ifelse(u < 0.5, 
                  rnorm(N, mean = -3, sd = 1), 
                  rnorm(N, mean = 3, sd = 1))
    content <- mean((eps >= lower - y) & (eps <= upper - y))
  } 
  
  if (model == 8){
    sd_x <- ifelse(x < 5, 1 + 0.5 * x, 2 - 0.3 * (x - 5))
    content <- pnorm(upper - y, mean = 0, sd = sd_x) - pnorm(lower - y, mean = 0, sd = sd_x)
  }
  return(content)
}

# hoeffding_simulation_Montecarlo
library(gam)
library(dplyr)
#--------------------------------------------- 시뮬레이션 설정
models <- 1:8
sample_sizes <- c(50, 100, 200)#, 500, 1000)
alpha <- 0.05 #1-confidence
delta <- 0.90 #content 
M <- 500

pointwise_coverage_result <- list()

for (model in models) {
  for (m in sample_sizes) {
    start_time <- Sys.time()
    content_matrix <- matrix(NA, nrow = m, ncol = M)
    
    for (i in 1:M) {
      set.seed(i)
      data <- generate_data(model, m)
      x <- data$x
      y <- data$y
      
      n_train <- m / 2
      n_cal <- m / 2
      
      all_indices <- sample(m)
      train_index <- all_indices[1:n_train]
      cal_index <- all_indices[(n_train + 1):m]
      
      train_x <- x[train_index]
      train_y <- y[train_index]
      cal_x <- x[cal_index]
      cal_y <- y[cal_index]
      
      # 평균 예측
      fit <- smooth.spline(x = train_x, y = train_y, cv = FALSE, tol = 1e-2)
      pred_y <- predict(fit, cal_x)$y
      
      # 분산 추정
      train_res <- train_y - predict(fit, train_x)$y
      log_res2 <- log(train_res^2 + 1e-6)
      gam_model <- gam(log_res2 ~ s(train_x))
      
      # 평균 함수
      fhat <- function(x_input) predict(fit, x_input)$y
      
      # 분산 함수
      sighat <- function(x_input) {
        log_pred <- predict(gam_model, newdata = data.frame(train_x = x_input))
        sqrt(exp(log_pred))
      }
      
      
      log_pred <- predict(gam_model, newdata = data.frame(train_x = cal_x))
      variance_hat <- exp(log_pred)
      
      # standardized residual score
      S <- abs(cal_y - pred_y) / sqrt(variance_hat)
      
      TI_upper <- TI_lower <- rep(NA, n_cal)
      for (k in 1:n_cal) {
        xj <- cal_x[k]
        #qj <- compute_local_q(S, cal_x, xj, delta, alpha, h = 0.5) #safe version
        qj <- compute_local_q_safe(S,cal_x, xj, delta, alpha, h0=0.5)
        if (is.na(qj)) next
        
        #center <- pred_y[k] #safe version
        #scale <- sqrt(variance_hat[k]) #safe version
        
        center <- fhat(xj) 
        scale <- sighat(xj)
        TI_upper[k] <- center + qj * scale
        TI_lower[k] <- center - qj * scale
      }
      
      for (k in 1:n_cal) {
        xj <- cal_x[k]
        j <- which.min(abs(x-xj))
        #j <- which(x == xj) #safe version
        if (is.na(TI_lower[k]) || is.na(TI_upper[k])) next
        content_matrix[j, i] <- content_function(model, TI_lower[k], TI_upper[k], xj)
      }
    }
    
    na_proportion <- rowMeans(is.na(content_matrix))
    coverage_proportion <- rowMeans(content_matrix >= 0.90, na.rm = TRUE)
    
    pointwise_coverage_result[[paste0("Model_", model, "_m_", m)]] <- data.frame(
      x = x,
      coverage = coverage_proportion,
      na_proportion = na_proportion
    )
    
    duration <- as.numeric(difftime(Sys.time(), start_time, units = "secs"))
    cat("[END] Model:", model, "Sample size:", m,
        round(duration, 2), "seconds", 
        "with coverage mean:", mean(coverage_proportion, na.rm = TRUE), 
        "NA proportion:", mean(na_proportion), "\n")
  }
}

# 결과 정리 및 시각화
pointwise_df <- do.call(rbind, lapply(names(pointwise_coverage_result), function(name) {
  if (!grepl("^Model_\\d+_m_\\d+$", name)) return(NULL)
  df <- pointwise_coverage_result[[name]]
  model <- as.integer(sub("Model_(\\d+)_.*", "\\1", name))
  m <- as.integer(sub(".*_m_(\\d+)", "\\1", name))
  df$Model <- model
  df$SampleSize <- m
  return(df)
}))

write.csv(pointwise_df, "0703_normal_safe_localized.csv", row.names = FALSE)


library(ggplot2)
ggplot(pointwise_df, aes(x = x, y = coverage)) +
  geom_point(size = 1) +
  facet_grid(Model ~ SampleSize, labeller = label_both) +
  geom_hline(yintercept = 0.95, linetype = "dashed", color = "red") +
  ylim(0, 1) +
  labs(
    title = "Pointwise Coverage (Content ≥ 0.90)",
    x = "x",
    y = "Proportion of simulations with content ≥ 0.90"
  ) +
  theme_bw()


#na proportion 
library(dplyr)

# 결과 리스트를 하나의 데이터프레임으로 병합
combined_na_df <- bind_rows(lapply(names(pointwise_coverage_result), function(name) {
  df <- pointwise_coverage_result[[name]]
  # 이름에서 model, m 추출
  parts <- strsplit(name, "_")[[1]]
  model <- as.integer(parts[2])
  m <- as.integer(parts[4])
  df$Model <- paste0("Model ", model)
  df$SampleSize <- paste0("n = ", m)
  return(df)
}))

# 시각화
ggplot(combined_na_df, aes(x = x, y = na_proportion)) +
  geom_line(size = 0.6) +
  facet_grid(Model ~ SampleSize, labeller = label_both) +
  ylim(0, 1) +
  labs(
    title = "Proportion of NA in Pointwise Coverage",
    x = "x",
    y = "Proportion of NA (Failed to Construct TI)"
  ) +
  theme_bw() +
  theme(legend.position = "none")
