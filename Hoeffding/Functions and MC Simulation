# hoeffding_simulation_Montecarlo
library(gam)

#---------------------------------------------필요한 함수 정의 
generate_data <- function(model, n) {
  x <- seq(0, 10, length.out = n)
  pop <- 3 * cos(x) - 5 * (x / 15)^2
  if (model == 1) {
    y <- 3 * cos(x) - 5 * (x / 15)^2 + rnorm(n, mean = 0, sd = sqrt(2))
  }
  if (model == 2) {
    y <- 3 * cos(x) - 5 * (x / 15)^2 + rnorm(n, mean = 0, sd = sqrt(2 * x))
  }
  if (model == 3) {
    y <- 3 * cos(x) - 5 * (x / 15)^2 + 4 - rgamma(n, shape = 2, scale = 2)
  }
  if (model == 4) {
    y <- 3 * cos(x) - 5 * (x / 15)^2 + rt(n, df = 3)
  }
  return(data.frame(x = x, y = y, pop = pop))
}

find_lambda_hat <- function(alpha, delta, y, pred, variance, n, lower=0, upper=5){
  f <- function(lambda, alpha, delta, y, pred, variance, n){
    risk <- mean(y <= pred - sqrt(variance)*lambda |
                   y >= pred + sqrt(variance)*lambda, na.rm=TRUE)
    threshold <- (1 - alpha) - sqrt(log(1/delta) / (2*n))
    return(risk - threshold)
  }
  lambda_hat <- tryCatch({
    uniroot(f, interval=c(lower, upper), alpha=alpha, delta=delta,
            y=y, pred=pred, variance=variance, n=n)$root
  }, error=function(e){
    optimize(function(lambda) f(lambda, alpha, delta, y, pred, variance, n),
             interval = c(lower, upper))$minimum
  })
  return(lambda_hat)
}
#------------------------------------------------------------------------------------------------
# 모델 번호와 샘플 크기 정의
models<-1:4
sample_sizes <- c(50, 100, 200, 500)

alpha <- 0.95
delta <- 0.90
M<-500

results <- data.frame()


for (model in models){
  for (n in sample_sizes){
    start_time <- Sys.time()
    
    picp_vec <- numeric(M)
    nmpiw_vec <- numeric(M)
    
    for (sim in 1:M){
      set.seed(sim+model*1000+n) #각 실행별로 시드 다르게 설정
    
      data <- generate_data(model, n)
      
      x <- data$x
      y <- data$y
      
      m <- nrow(data)
      n_test <- n/2
      n_train <- floor(n/4)
      n_cal <- n - n_test - n_train
    
      # 데이터 샘플링
      all_indices <- sample(n)
      train_index <- all_indices[1:n_train]
      cal_index <- all_indices[(n_train + 1):(n_train + n_cal)]
      test_index <- all_indices[(n_train + n_cal + 1):n]
      
      train_x <- x[train_index]
      train_y <- y[train_index]
      cal_x <- x[cal_index]
      cal_y <- y[cal_index]
      test_x <- x[test_index]
      test_y <- y[test_index]
    
      # 1. 훈련 데이터를 이용해 모델 학습 (평균 예측값 계산)
      fit <- smooth.spline(x = train_x, y = train_y, cv = FALSE)
      cal_mean_pred <- predict(fit, cal_x)$y  # mean prediction
      
      # 2. Calibration 데이터로 예측 오차의 분산 추정 (log scale로)
      train_res <- train_y - predict(fit, train_x)$y
      log_res2 <- log(train_res^2+1e-10)
      gam_model <- gam(log_res2 ~ s(train_x))
      log_pred <- predict(gam_model, newdata = data.frame(train_x = cal_x))
      cal_variance <- exp(log_pred) # 분산 추정값
      
      # 3. Tolerance Interval 계산 (분산을 포함한 계산)
      # 예시로 lambda_hat는 보통 특정 확률값을 기준으로 계산
      lambda_hat <- find_lambda_hat(alpha,delta , cal_y, cal_mean_pred, cal_variance, length(cal_y))
      
      TI_upper <- cal_mean_pred + sqrt(cal_variance) * lambda_hat
      TI_lower <- cal_mean_pred - sqrt(cal_variance) * lambda_hat
      
      train_coverage <- (cal_y >= TI_lower) & (cal_y <= TI_upper)
      
      # 4. 선형 보간을 이용해 test 데이터가 TI 구간에 포함되는지 계산 (PICP 계산)
      TI_lower_df <- aggregate(TI_lower ~ cal_x, FUN = mean)
      TI_upper_df <- aggregate(TI_upper ~ cal_x, FUN = mean)
      
      # 선형 보간
      interp_lower <- approx(x = TI_lower_df$cal_x, y = TI_lower_df$TI_lower, xout = test_x)$y
      interp_upper <- approx(x = TI_upper_df$cal_x, y = TI_upper_df$TI_upper, xout = test_x)$y
    
      # test_x에 대해 예측값이 TI 구간에 포함되었는지 여부 확인
      included <- (test_y >= interp_lower) & (test_y <= interp_upper)
      picp_vec[sim] <- mean(included, na.rm=TRUE)
      
      # NMPIW 계산
      interval_width <- interp_upper - interp_lower
      y_range <- max(test_y) - min(test_y)
      nmpiw_vec[sim]  <- mean(interval_width, na.rm = TRUE) / y_range
    }
    
    end_time <- Sys.time()
    
    PICP_mean <- mean(picp_vec)
    NMPIW_mean <- mean(nmpiw_vec)
    
    results <- rbind(results, data.frame(model = model, sample_size = n,
                                         PICP_mean = PICP_mean,
                                         NMPIW_mean = NMPIW_mean
    ))
    
    elapsed <- round(difftime(end_time, start_time, units='secs'), 2)
    cat(sprintf("[DONE] Model %d, n = %d | PICP = %.4f | NMPIW = %.4f | Time = %s sec\n",
                model, n, PICP_mean, NMPIW_mean, elapsed))
  }
}

# 결과 정리해서 출력 
library(dplyr)
result_summary <- results %>%
  mutate(PICP_mean = round(PICP_mean, 4), NMPIW_mean = round(NMPIW_mean, 4)
  ) %>%
  arrange(model, sample_size)
print(result_summary)

