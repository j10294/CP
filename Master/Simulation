# =========================================================
# Global CP vs CC-CP vs SCC-CP (R simulation, cleaned)
# =========================================================

suppressPackageStartupMessages({
  library(nnet)       # multinom
  library(dplyr)
  library(tidyr)
  library(purrr)
  library(ggplot2)
  library(MASS)
  library(progress)
})

set.seed(1)

# ----------------------------
# 1) Basic utilities
# ----------------------------

# Quantile for conformal scores
conformal_quantile <- function(scores, alpha) {
  scores <- sort(as.numeric(scores))
  n <- length(scores)
  if (n == 0) return(Inf)
  k <- ceiling((n + 1) * (1 - alpha))
  k <- max(min(k, n), 1)
  scores[k]
}

# Per-class coverage variance helper
.safe_cov_variance <- function(per_class_cov, overall_cov, n_k) {
  ok <- is.finite(per_class_cov) & (n_k > 0)
  if (!any(ok)) return(NA_real_)
  mean((per_class_cov[ok] - overall_cov)^2)
}

# Metrics: overall + set size + per-class
eval_metrics <- function(pred_sets, y_true, K) {
  covered <- map2_lgl(pred_sets, y_true, ~ (.y %in% .x))
  overall_cov <- mean(covered)
  
  set_sizes <- vapply(pred_sets, length, integer(1))
  mean_set_size   <- mean(set_sizes)
  median_set_size <- median(set_sizes)
  
  n_k <- tabulate(y_true, nbins = K)
  per_class_cov <- vapply(seq_len(K), function(k) {
    if (n_k[k] == 0) return(NA_real_)
    mean(covered[y_true == k])
  }, numeric(1))
  per_class <- tibble::tibble(
    class = seq_len(K),
    n_k   = n_k,
    cov   = per_class_cov
  )
  
  coverage_variance <- .safe_cov_variance(per_class$cov, overall_cov, per_class$n_k)
  worst_class_cov <- if (any(per_class$n_k > 0)) {
    min(per_class$cov[per_class$n_k > 0], na.rm = TRUE)
  } else {
    NA_real_
  }
  
  tibble::tibble(
    overall_cov = overall_cov,
    mean_set_size = mean_set_size,
    median_set_size = median_set_size,
    cov_var_across_classes = coverage_variance,
    worst_class_cov = worst_class_cov,
    coverage_variance = coverage_variance
  ) %>% tibble::add_column(per_class = list(per_class))
}

# Class-wise coverage/size (for plotting)
compute_classwise <- function(predsets, true_y, K) {
  out <- lapply(seq_len(K), function(k){
    idx <- which(true_y == k)
    if (length(idx) == 0) {
      return(data.frame(class = k,
                        class_cov = NA_real_,
                        class_size = NA_real_))
    }
    cov_k <- mean(sapply(idx, function(i) k %in% predsets[[i]]))
    size_k <- mean(sapply(idx, function(i) length(predsets[[i]])))
    data.frame(class = k,
               class_cov = cov_k,
               class_size = size_k)
  })
  do.call(rbind, out)
}

# ----------------------------
# 2) Prediction set builders
# ----------------------------

# Global CP: one threshold for all labels (returns label values)
build_pred_set_global <- function(p_row, qG) {
  labels <- as.integer(names(p_row))  # colnames(p_mat) → labels
  s_vec  <- 1 - p_row
  labels[s_vec <= qG]
}

# Cluster-wise CP: cluster-specific thresholds (returns label values)
build_pred_set_cluster <- function(p_row, label_clusters, q_by_cluster) {
  labels <- as.integer(names(p_row))           # label IDs (1..K)
  s_vec  <- 1 - p_row
  cl_ids <- label_clusters[labels]            # class → cluster
  th_vec <- q_by_cluster[cl_ids]
  labels[s_vec <= th_vec]
}

# ----------------------------
# 3) Label clustering (k-means on score embeddings)
# ----------------------------

label_kmeans <- function(scores_by_label,
                         Kc = 5,
                         alpha = 0.05,
                         quantiles = c(.1, .3, .5, .7, .9, 1 - alpha)) {
  quantiles <- sort(unique(quantiles))
  K <- length(scores_by_label)
  emb <- matrix(NA_real_, nrow = K, ncol = length(quantiles))
  
  for (k in seq_len(K)) {
    v <- scores_by_label[[k]]
    if (length(v) < 5) {
      v <- c(v, rep(median(v, na.rm = TRUE), 5 - length(v)))
    }
    emb[k, ] <- quantile(v, probs = quantiles, na.rm = TRUE, type = 8)
  }
  
  Kc_eff <- min(Kc, K)
  if (Kc_eff < 1) stop("label_kmeans: effective Kc < 1.")
  
  km <- kmeans(scale(emb), centers = Kc_eff, nstart = 10)
  km$cluster  # length K, values 1..Kc_eff
}

# Merge very small clusters into the largest one
merge_small_clusters <- function(label_clusters, y_cal, m_min = 100) {
  cl_idx <- label_clusters[y_cal]
  cl_counts <- tabulate(cl_idx, nbins = max(label_clusters))
  small <- which(cl_counts < m_min)
  if (length(small) == 0) return(label_clusters)
  
  big <- which.max(cl_counts)
  lab <- label_clusters
  for (c in small) {
    lab[lab == c] <- big
  }
  uniq <- sort(unique(lab))
  match(lab, uniq)  # relabel to 1..Kc_eff
}

# ----------------------------
# 4) Helpers for aggregating over repetitions
# ----------------------------

.pull_scalar_metrics <- function(res_list, tag) {
  purrr::map_dfr(res_list, function(r) {
    x <- tibble::as_tibble(r[[tag]])
    x %>%
      dplyr::select(overall_cov, mean_set_size, median_set_size,
                    cov_var_across_classes, worst_class_cov) %>%
      dplyr::slice(1)
  })
}

.pull_per_class_tbl_one_run <- function(run, method_key) {
  x <- run[[method_key]]
  if (is.null(x)) return(tibble::tibble())
  x <- tibble::as_tibble(x)
  
  if (all(c("class", "cov") %in% names(x))) {
    x %>%
      dplyr::select(class, cov) %>%
      dplyr::mutate(method = dplyr::case_when(
        method_key == "GCP"  ~ "Global",
        method_key == "CCCP" ~ "CC-CP",
        method_key == "SCCP" ~ "SCC-CP",
        TRUE ~ method_key
      ))
  } else if ("per_class" %in% names(x)) {
    pc <- tryCatch(x$per_class[[1]], error = function(e) NULL)
    if (is.null(pc)) return(tibble::tibble())
    tibble::as_tibble(pc) %>%
      dplyr::mutate(method = dplyr::case_when(
        method_key == "GCP"  ~ "Global",
        method_key == "CCCP" ~ "CC-CP",
        method_key == "SCCP" ~ "SCC-CP",
        TRUE ~ method_key
      ))
  } else {
    tibble::tibble()
  }
}

.compute_clusterwise_cov_one_run <- function(run) {
  lc <- run$label_clusters
  if (is.null(lc)) return(tibble::tibble())
  methods <- c("GCP", "CCCP", "SCCP")
  
  per_class_all <- purrr::map_dfr(methods, ~ .pull_per_class_tbl_one_run(run, .x))
  if (nrow(per_class_all) == 0) return(tibble::tibble())
  
  map_tbl <- tibble::tibble(class = seq_along(lc), cluster = lc)
  
  per_class_all %>%
    dplyr::left_join(map_tbl, by = "class") %>%
    dplyr::group_by(method, cluster) %>%
    dplyr::summarise(cluster_cov = mean(cov, na.rm = TRUE), .groups = "drop")
}

# ----------------------------
# 5) Lambda selection on selection split
# ----------------------------

choose_lambda_by_selection <- function(
    p_sel,
    y_sel,
    label_clusters_sel,
    alpha,
    qC_sel,
    qG_sel,
    grid = seq(0, 1, by = 0.1)
) {
  Kc <- length(unique(label_clusters_sel))
  best_lambda <- rep(NA_real_, Kc)
  
  # 한 번 계산해두고, 각 클러스터가 공통으로 사용
  make_eval <- function(lmb) {
    q_star <- (1 - lmb) * qC_sel + lmb * qG_sel
    
    pred_sets <- lapply(seq_len(nrow(p_sel)), function(i) {
      build_pred_set_cluster(p_sel[i, ], label_clusters_sel, q_star)
    })
    
    covered <- mapply(function(ps, y) y %in% ps, pred_sets, y_sel)
    
    list(pred_sets = pred_sets, covered = covered)
  }
  
  cand_lmb <- sort(unique(grid))
  cand     <- lapply(cand_lmb, make_eval)
  
  mean_size_vec <- sapply(cand, function(o) {
    mean(sapply(o$pred_sets, length))
  })
  
  for (cc in seq_len(Kc)) {
    idx_cc <- which(label_clusters_sel[y_sel] == cc)
    
    # selection 데이터에 이 클러스터가 아예 없으면 → 보수적으로 global
    if (length(idx_cc) == 0) {
      best_lambda[cc] <- 1
      next
    }
    
    cov_cc_vec <- sapply(cand, function(o) {
      mean(o$covered[idx_cc])
    })
    
    eval_tbl <- tibble::tibble(
      lambda    = cand_lmb,
      mean_size = mean_size_vec,
      cov_cc    = cov_cc_vec
    )
    
    # (1) 클러스터 커버리지가 1 - alpha 이상인 후보들 중
    #     set size 최소(그다음 cov 큰 것) 선택
    feas <- dplyr::filter(eval_tbl, cov_cc >= (1 - alpha))
    
    if (nrow(feas) > 0) {
      chosen <- feas %>%
        dplyr::arrange(mean_size, dplyr::desc(cov_cc)) %>%
        dplyr::slice(1)
    } else {
      # (2) 그런 λ가 없으면 cov 최대(그다음 size 작은 것) 선택
      chosen <- eval_tbl %>%
        dplyr::arrange(dplyr::desc(cov_cc), mean_size) %>%
        dplyr::slice(1)
    }
    
    best_lambda[cc] <- chosen$lambda
  }
  
  # 혹시라도 NA 남아 있으면 전체 global 로 fallback
  best_lambda[is.na(best_lambda)] <- 1
  
  best_lambda   # length Kc 벡터
}



# ----------------------------
# 6) Data generator
# ----------------------------
gen_data <- function(n, K = 50, d = 10,
                     prior = c("balanced","zipf"),
                     noise = c("homog","hetero","hetero_tail"),
                     sep = 1.8) {
  prior <- match.arg(prior)
  noise <- match.arg(noise)
  
  ## 1) class priors
  if (prior == "balanced") {
    pi_k <- rep(1 / K, K)
  } else {
    # Zipf-like
    pi_k <- 1 / (1:K)^1.1
    pi_k <- pi_k / sum(pi_k)
  }
  
  ## 2) 기본 방향 벡터 (길이 1인 random direction)
  base_mus <- matrix(rnorm(K * d), K, d)
  base_mus <- sweep(base_mus, 1, sqrt(rowSums(base_mus^2)), "/")
  
  ## 3) "난이도" 정의: 자주 나올수록 easy, tail일수록 hard
  #   rank_pi: prior가 큰 순으로 1,2,... (1=가장 frequent)
  rank_pi   <- rank(-pi_k, ties.method = "first")
  difficulty <- (rank_pi - 1) / (K - 1)   # 0(head) ~ 1(tail)
  
  mus    <- matrix(NA_real_, K, d)
  sigmas <- vector("list", K)
  
  ## 4) noise 타입별 mean / covariance
  if (noise == "homog") {
    # 완전히 동일한 분산, sep만 고정
    for (k in 1:K) {
      mus[k, ]    <- sep * base_mus[k, ]
      sigmas[[k]] <- diag(d)
    }
    
  } else if (noise == "hetero") {
    # 기존처럼 클래스별 분산만 랜덤
    for (k in 1:K) {
      mus[k, ] <- sep * base_mus[k, ]
      s        <- runif(1, 0.5, 3.0)
      sigmas[[k]] <- diag(d) * s
    }
    
  } else if (noise == "hetero_tail") {
    # head: sep 크고 variance 작음 (easy)
    # tail: sep 줄이고 variance 크게 (hard)
    for (k in 1:K) {
      diff_k <- difficulty[k]          # 0(head) ~ 1(tail)
      
      # tail로 갈수록 sep를 줄여서(mean을 서로 더 붙게)
      #   head: sep_k ≈ 1.1 * sep
      #   tail: sep_k ≈ 0.4 * sep
      sep_k <- sep * (1.1 - 0.7 * diff_k)
      
      # tail로 갈수록 분산 크게:
      #   head: scale ≈ 0.7
      #   tail: scale ≈ 6
      scale_k <- 0.7 + 5.3 * diff_k^2
      
      mus[k, ]    <- sep_k * base_mus[k, ]
      sigmas[[k]] <- diag(d) * scale_k
    }
  }
  
  ## 5) 샘플링
  y <- sample(seq_len(K), size = n, replace = TRUE, prob = pi_k)
  X <- matrix(NA_real_, n, d)
  for (i in seq_len(n)) {
    k <- y[i]
    X[i, ] <- MASS::mvrnorm(1, mu = mus[k, ], Sigma = sigmas[[k]])
  }
  
  list(X = X, y = y)
}


# ----------------------------
# 7) One simulation run
# ----------------------------

run_once <- function(K = 50, d = 10, n_train = 4000, n_select = 2000,
                     n_calib = 2000, n_test = 4000,
                     prior = "zipf", noise = "hetero",
                     alpha = 0.05, Kc = 5, seed = 1) {
  
  set.seed(seed)
  
  Dtr  <- gen_data(n_train, K, d, prior, noise)
  Dsel <- gen_data(n_select, K, d, prior, noise)
  Dca  <- gen_data(n_calib, K, d, prior, noise)
  Dte  <- gen_data(n_test,  K, d, prior, noise)
  
  Xtr  <- as.data.frame(Dtr$X);  colnames(Xtr)  <- paste0("x", seq_len(ncol(Xtr)))
  Xsel <- as.data.frame(Dsel$X); colnames(Xsel) <- colnames(Xtr)
  Xca  <- as.data.frame(Dca$X);  colnames(Xca)  <- colnames(Xtr)
  Xte  <- as.data.frame(Dte$X);  colnames(Xte)  <- colnames(Xtr)
  
  y_tr  <- Dtr$y
  y_sel <- Dsel$y
  y_cal <- Dca$y
  y_te  <- Dte$y
  
  df_train <- data.frame(y = factor(y_tr), Xtr)
  mod <- nnet::multinom(y ~ ., data = df_train,
                        trace = FALSE, MaxNWts = 10000)
  
  ## ---- (3) 예측 확률 계산 ----
  p_sel <- as.matrix(predict(mod, newdata = Xsel, type = "probs"))
  p_cal <- as.matrix(predict(mod, newdata = Xca,  type = "probs"))
  p_tst <- as.matrix(predict(mod, newdata = Xte,  type = "probs"))
  
  ## ---- (3-1) y 벡터를 따로 저장 ----
  y_sel <- Dsel$y
  y_cal <- Dca$y
  y_te  <- Dte$y
  
  ## ---- (3-2) train에서 실제로 학습된 클래스만 사용 ----
  valid_classes <- colnames(p_sel)          # multinom이 예측하는 클래스들 (문자)
  
  keep_sel <- as.character(y_sel) %in% valid_classes
  keep_cal <- as.character(y_cal) %in% valid_classes
  keep_te  <- as.character(y_te)  %in% valid_classes
  
  if (any(!keep_sel)) {
    message("Dropping ", sum(!keep_sel), " selection samples with unseen classes.")
  }
  if (any(!keep_cal)) {
    message("Dropping ", sum(!keep_cal), " calibration samples with unseen classes.")
  }
  if (any(!keep_te)) {
    message("Dropping ", sum(!keep_te), " test samples with unseen classes.")
  }
  
  # 실제로 필터링: y와 p_*만 확실하게 맞춰준다
  y_sel <- y_sel[keep_sel]
  y_cal <- y_cal[keep_cal]
  y_te  <- y_te[keep_te]
  
  p_sel <- p_sel[keep_sel, , drop = FALSE]
  p_cal <- p_cal[keep_cal, , drop = FALSE]
  p_tst <- p_tst[keep_te,  , drop = FALSE]
  
  
  # 이름: 열 이름 = 클래스 라벨 (문자)
  colnames(p_sel) <- colnames(p_cal) <- colnames(p_tst)
  
  # true-label prob extractor (uses names, no data.frame 서브셋)
  get_true_prob <- function(p_mat, y) {
    y_chr   <- as.character(y)
    col_idx <- match(y_chr, colnames(p_mat))
    if (any(is.na(col_idx))) {
      missing_labels <- unique(y_chr[is.na(col_idx)])
      stop("Some labels in y are not found in colnames(p_mat): ",
           paste(missing_labels, collapse = ", "))
    }
    p_mat[cbind(seq_len(nrow(p_mat)), col_idx)]
  }
  
  s_sel_true <- 1 - get_true_prob(p_sel, y_sel)
  s_cal_true <- 1 - get_true_prob(p_cal, y_cal)
  
  # ----- Global CP -----
  qG_cal <- conformal_quantile(s_cal_true, alpha)
  
  predsets_GCP <- lapply(seq_len(nrow(p_tst)), function(i) {
    pr <- p_tst[i, ]
    pr_named <- pr; names(pr_named) <- colnames(p_tst)
    build_pred_set_global(pr_named, qG_cal)
  })
  
  metrics_GCP    <- eval_metrics(predsets_GCP, y_te, K)
  classwise_GCP  <- compute_classwise(predsets_GCP, y_te, K)
  
  # ----- CC-CP -----
  scores_by_label_cal <- split(s_cal_true, y_cal)  # assumes labels 1..K all appear
  label_clusters <- label_kmeans(scores_by_label_cal, Kc = Kc,
                                 alpha = alpha,
                                 quantiles = c(.1,.3,.5,.7,.9,1-alpha))
  label_clusters <- merge_small_clusters(label_clusters, y_cal, m_min = 100)
  Kc_eff <- length(unique(label_clusters))
  
  qC_cal <- sapply(seq_len(Kc_eff), function(cc) {
    idx <- which(label_clusters[y_cal] == cc)
    conformal_quantile(s_cal_true[idx], alpha)
  })
  size_cc <- sapply(seq_len(Kc_eff), function(cc) sum(label_clusters[y_cal] == cc))
  tau <- 0.0 + 0.05 * as.numeric(size_cc < 150) + 0.03 * as.numeric(size_cc < 80)
  qC_cal_safe <- qC_cal + tau
  
  predsets_CCCP <- lapply(seq_len(nrow(p_tst)), function(i) {
    pr <- p_tst[i, ]
    pr_named <- pr; names(pr_named) <- colnames(p_tst)
    build_pred_set_cluster(pr_named, label_clusters, qC_cal_safe)
  })
  
  metrics_CCCP    <- eval_metrics(predsets_CCCP, y_te, K)
  classwise_CCCP  <- compute_classwise(predsets_CCCP, y_te, K)
  
  # ----- SCC-CP (shrinkage) -----
  scores_by_label_sel <- split(s_sel_true, y_sel)
  
  qC_sel <- sapply(seq_len(Kc_eff), function(cc) {
    idx <- which(label_clusters[y_sel] == cc)
    conformal_quantile(s_sel_true[idx], alpha)
  })
  qG_sel <- conformal_quantile(s_sel_true, alpha)
  
  lambda_hat <- choose_lambda_by_selection(
    p_sel              = p_sel,
    y_sel              = Dsel$y,
    label_clusters_sel = label_clusters,
    alpha              = alpha,
    qC_sel             = qC_sel,
    qG_sel             = qG_sel,
    grid               = seq(0, 1, by = 0.1)
  )
  
  q_star <- (1 - lambda_hat) * qC_cal_safe + lambda_hat * qG_cal
  
  predsets_SCCP <- lapply(seq_len(nrow(p_tst)), function(i) {
    pr <- p_tst[i, ]
    pr_named <- pr; names(pr_named) <- colnames(p_tst)
    build_pred_set_cluster(pr_named, label_clusters, q_star)
  })
  
  metrics_SCCP    <- eval_metrics(predsets_SCCP, y_te, K)
  classwise_SCCP  <- compute_classwise(predsets_SCCP, y_te, K)
  
  list(
    GCP   = c(metrics_GCP,  list(classwise = classwise_GCP)),
    CCCP  = c(metrics_CCCP, list(classwise = classwise_CCCP)),
    SCCP  = c(metrics_SCCP, list(classwise = classwise_SCCP)),
    lambda_hat = lambda_hat,
    qG_cal = qG_cal, qC_cal = qC_cal_safe, q_star = q_star,
    label_clusters = label_clusters
  )
}

# ----------------------------
# 8) Multiple repetitions for one (K, Kc, ...) combo
# ----------------------------

run_many <- function(R = 10,
                     K = 50, d = 5,
                     n_train = 6000, n_select = 4000,
                     n_calib = 4000, n_test = 6000,
                     prior = "zipf", noise = "hetero",
                     alpha = 0.05, Kc = 6) {
  
  seeds <- sample(1:9999, R, replace = FALSE)
  res_list <- purrr::map(seeds, ~ run_once(
    K=K, d=d, n_train=n_train, n_select=n_select, n_calib=n_calib, n_test=n_test,
    prior=prior, noise=noise, alpha=alpha, Kc=Kc, seed=.x
  ))
  
  agg_scalar <- dplyr::bind_rows(
    .pull_scalar_metrics(res_list, "GCP")  %>% dplyr::mutate(method = "Global"),
    .pull_scalar_metrics(res_list, "CCCP") %>% dplyr::mutate(method = "CC-CP"),
    .pull_scalar_metrics(res_list, "SCCP") %>% dplyr::mutate(method = "SCC-CP")
  )
  
  summary_overall <- agg_scalar %>%
    dplyr::group_by(method) %>%
    dplyr::summarise(
      overall_cov = mean(overall_cov, na.rm = TRUE),
      mean_set_size = mean(mean_set_size, na.rm = TRUE),
      median_set_size = mean(median_set_size, na.rm = TRUE),
      cov_var_across_classes = mean(cov_var_across_classes, na.rm = TRUE),
      worst_class_cov = mean(worst_class_cov, na.rm = TRUE),
      .groups = "drop"
    )
  
  clusterwise_all <- purrr::map_dfr(seq_along(res_list), function(i) {
    .compute_clusterwise_cov_one_run(res_list[[i]]) %>%
      dplyr::mutate(rep = i)
  })
  
  summary_clusterwise <- clusterwise_all %>%
    dplyr::group_by(method, cluster) %>%
    dplyr::summarise(
      mean_cluster_cov = mean(cluster_cov, na.rm = TRUE),
      .groups = "drop"
    )
  
  classwise_all <- purrr::map_dfr(seq_along(res_list), function(i) {
    r <- res_list[[i]]
    dplyr::bind_rows(
      r$GCP$classwise  %>% dplyr::mutate(method = "Global"),
      r$CCCP$classwise %>% dplyr::mutate(method = "CC-CP"),
      r$SCCP$classwise %>% dplyr::mutate(method = "SCC-CP")
    ) %>% dplyr::mutate(rep = i)
  })
  
  summary_classwise <- classwise_all %>%
    dplyr::group_by(method, class) %>%
    dplyr::summarise(
      mean_class_cov  = mean(class_cov, na.rm = TRUE),
      mean_class_size = mean(class_size, na.rm = TRUE),
      .groups = "drop"
    )
  
  list(
    overall     = summary_overall,
    clusterwise = summary_clusterwise,
    classwise   = summary_classwise,
    runs        = res_list
  )
}

# ----------------------------
# 9) Full simulation over (K, Kc) grid
# ----------------------------

grid <- tidyr::expand_grid(
  K    = c(30, 50),
  Kc   = c(3, 5, 7, 10),
  d    = 10,
  noise = c("hetero"),
  prior = "zipf"
) %>%
  filter(!(K == 30 & Kc == 10))


n_reps <- 50
seeds  <- 1:n_reps
alpha <- 0.05

run_one_combo <- function(K, Kc, d, noise, prior, seed) {
  set.seed(seed)
  out <- run_many(
    R         = 1,
    K         = K,
    d         = d,
    n_train   = 4000,
    n_select  = 2000,
    n_calib   = 2000,
    n_test    = 4000,
    prior     = prior,
    noise     = noise,
    alpha     = alpha,
    Kc        = Kc
  )
  out$overall     <- out$overall     %>% mutate(K = K, Kc = Kc, d = d, noise = noise, prior = prior, seed = seed)
  out$clusterwise <- out$clusterwise %>% mutate(K = K, Kc = Kc, d = d, noise = noise, prior = prior, seed = seed)
  out$classwise   <- out$classwise   %>% mutate(K = K, Kc = Kc, d = d, noise = noise, prior = prior, seed = seed)
  out
}

total_tasks <- nrow(grid) * n_reps
pb <- progress_bar$new(
  total = total_tasks,
  format = "[:bar] :percent ETA: :eta (K=:K Kc=:Kc d=:d noise=:noise prior=:prior seed=:seed)"
)

all_runs <- list()
for (i in seq_len(nrow(grid))) {
  g <- grid[i, ]
  for (s in seeds) {
    pb$tick(tokens = list(
      K    = g$K,
      Kc   = g$Kc,
      d    = g$d,
      noise = g$noise,
      prior = g$prior,
      seed  = s
    ))
    result <- run_one_combo(
      K     = g$K,
      Kc    = g$Kc,
      d     = g$d,
      noise = g$noise,
      prior = g$prior,
      seed  = s
    )
    all_runs <- append(all_runs, list(result))
  }
}

lambda_df <- purrr::map_dfr(all_runs, function(res_combo) {
  purrr::map_dfr(res_combo$runs, function(run) {
    tibble(
      K        = run$K,
      Kc       = length(unique(run$label_clusters)),
      cluster  = seq_along(run$lambda_hat),
      lambda   = run$lambda_hat
    )
  })
})
lambda_df %>% count(lambda)
ggplot(lambda_df, aes(lambda)) + geom_histogram(binwidth=0.1)


# =========================================================
# 결과 정리: overall / clusterwise / classwise
# =========================================================


library(dplyr)
library(purrr)
library(tidyr)

# all_runs: 앞에서 시뮬 돌릴 때 쌓아둔 리스트 (각 요소가 run_one_combo 결과)

final_overall <- all_runs %>%
  map(~ .x$overall) %>%
  purrr::compact() %>%
  list_rbind()

final_cluster <- all_runs %>%
  map(~ .x$clusterwise) %>%
  purrr::compact() %>%
  list_rbind()

final_class <- all_runs %>%
  map(~ .x$classwise) %>%
  purrr::compact() %>%
  list_rbind()

cat("# rows\n")
cat("final_overall:", nrow(final_overall), "\n")
cat("final_cluster:", nrow(final_cluster), "\n")
cat("final_class  :", nrow(final_class), "\n")

# =========================================================
# 시각화
# =========================================================

library(ggplot2)
library(scales)

method_levels  <- c("Global","CC-CP","SCC-CP")

theme_paper <- function(base_size = 11){
  theme_bw(base_size = base_size) +
    theme(
      panel.grid.minor = element_blank(),
      panel.grid.major.x = element_blank(),
      strip.background = element_rect(fill = "white", colour = "black", linewidth = 0.5),
      strip.text = element_text(face = "bold"),
      legend.position = "top",
      legend.title = element_blank(),
      legend.key = element_blank(),
      panel.spacing = unit(6, "pt")
    )
}

col_vals   <- c("Global"="black","CC-CP"="grey35","SCC-CP"="grey10")
lty_vals   <- c("Global"="solid","CC-CP"="dashed","SCC-CP"="dotdash")
shape_vals <- c("Global"=16, "CC-CP"=1, "SCC-CP"=17)

y_scale_cov <- scale_y_continuous(
  labels = percent_format(accuracy = 1),
  limits = c(0.6, 1.0),
  breaks = seq(0.6, 1.0, by = 0.1)
)

Ks_to_plot <- sort(unique(final_overall$K))
d_vals     <- sort(unique(final_overall$d))
noise_vals <- sort(unique(final_overall$noise))   # ==> c("hetero", "hetero_tail")

# --------------------------------------------------
# 1) Overall plot
# --------------------------------------------------
for (noise0 in noise_vals) {
  for (d0 in d_vals) {
    for (K0 in Ks_to_plot) {
      
      df_overall <- final_overall %>%
        filter(prior == "zipf",
               noise == noise0,
               d == d0,
               K == K0)
      
      if (nrow(df_overall) == 0) next
      
      plot_overall_dK <- df_overall %>%
        mutate(
          method   = factor(method, levels = method_levels),
          Kc_label = factor(paste0("Kc=", Kc),
                            levels = c("Kc=3","Kc=5","Kc=7","Kc=10"))
        ) %>%
        group_by(method, Kc_label) %>%
        summarise(mean_cov = mean(overall_cov, na.rm = TRUE),
                  .groups  = "drop") %>%
        ggplot(aes(x = method, y = mean_cov,
                   colour = method, shape = method)) +
        geom_point(size = 2.3, fill = "white", stroke = 0.8) +
        geom_hline(yintercept = 0.95, linetype = "dotted", linewidth = 0.6) +
        facet_wrap(~ Kc_label, nrow = 1) +
        y_scale_cov +
        scale_colour_manual(values = col_vals) +
        scale_shape_manual(values  = shape_vals) +
        labs(
          x = "Method",
          y = "Coverage",
          title = paste0("Overall Coverage (Zipf, ", noise0,
                         ", d=", d0, ", K=", K0, ")")
        ) +
        theme_paper()
      
      ggsave(
        filename = sprintf("fig/overall_zipf_%s_d%d_K%d.png",
                           noise0, d0, K0),
        plot     = plot_overall_dK,
        width    = 7, height = 3.5, dpi = 300, bg = "white"
      )
    }
  }}

# --------------------------------------------------
# 2) Clusterwise plot
# --------------------------------------------------
for (noise0 in noise_vals) {
  for (d0 in d_vals) {
    for (K0 in Ks_to_plot) {
      
      df_cluster <- final_cluster %>%
        filter(prior == "zipf",
               noise == noise0,
               d == d0,
               K == K0)
      
      if (nrow(df_cluster) == 0) next
      
      plot_cluster_dK <- df_cluster %>%
        mutate(
          method   = factor(method, levels = method_levels),
          cluster  = as.factor(cluster),
          Kc_label = factor(paste0("Kc=", Kc),
                            levels = c("Kc=3","Kc=5","Kc=7","Kc=10"))
        ) %>%
        group_by(method, Kc_label, cluster) %>%
        summarise(mean_cov = mean(mean_cluster_cov, na.rm = TRUE),
                  .groups  = "drop") %>%
        ggplot(aes(x = cluster, y = mean_cov,
                   group = method, colour = method,
                   linetype = method)) +
        geom_line(linewidth = 0.7) +
        geom_point(aes(shape = method), size = 1.8, stroke = 0.8) +
        geom_hline(yintercept = 0.95, linetype = "dotted", linewidth = 0.6) +
        facet_wrap(~ Kc_label, nrow = 1) +
        scale_colour_manual(values = col_vals) +
        scale_linetype_manual(values= lty_vals) +
        scale_shape_manual(values= shape_vals) +
        y_scale_cov +
        labs(
          x = "Cluster",
          y = "Coverage",
          title = paste0("Cluster-wise Coverage (Zipf, ", noise0,
                         ", d=", d0, ", K=", K0, ")")
        ) +
        theme_paper()
      
      ggsave(
        filename = sprintf("fig/cluster_zipf_%s_d%d_K%d.png",
                           noise0, d0, K0),
        plot     = plot_cluster_dK,
        width    = 7, height = 3.5, dpi = 300, bg = "white"
      )
    }
  }}

# --------------------------------------------------
# 3) Coverage Report
# --------------------------------------------------

coverage_report<- final_class %>%
  filter(prior == "zipf") %>%  
  group_by(d, method, K, Kc) %>% 
  summarise(
    prop_over95 = mean(mean_class_cov >= 0.95, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(
    prop_percent = percent(prop_over95, accuracy = 0.1)
  ) %>%
  dplyr::select(d, K, Kc, method, prop_percent)

xt <- xtable(
  coverage_report,
  caption = "Fraction of classes whose coverage exceeded the 0.95 target.",
  label   = "tab:over95-simple",
  digits  = 3
)

print(
  xt,
  file = "table/1119_coverage_table.tex",
  include.rownames = FALSE,
  booktabs = TRUE,
  sanitize.text.function = identity
)

